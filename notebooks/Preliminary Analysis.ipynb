{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNPL Data timeline: 2021-2-28 to 2022-10-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import* \n",
    "from pyspark.sql.functions import regexp_replace, col, trim, split\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Preliminary Analysis\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.driver.memory\",\"4G\")\n",
    "    .config(\"spark.executor.memory\",\"4G\")\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNPL dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merchant datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fraud = spark.read.csv('../data/tables/tables 1/merchant_fraud_probability.csv', header=True, inferSchema=True)\n",
    "tbl_merchants = spark.read.parquet('../data/tables/tables 1/tbl_merchants.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4026"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(merchant_fraud.select('merchant_abn').distinct().count())\n",
    "tbl_merchants.select('merchant_abn').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Merchant datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----------------+--------------------+--------------------+\n",
      "|merchant_abn|order_datetime|fraud_probability|                name|                tags|\n",
      "+------------+--------------+-----------------+--------------------+--------------------+\n",
      "| 10023283211|          NULL|             NULL|       Felis Limited|((furniture, home...|\n",
      "| 10142254217|          NULL|             NULL|Arcu Ac Orci Corp...|([cable, satellit...|\n",
      "| 10165489824|          NULL|             NULL|    Nunc Sed Company|([jewelry, watch,...|\n",
      "| 10187291046|          NULL|             NULL|Ultricies Digniss...|([wAtch, clock, a...|\n",
      "| 10192359162|          NULL|             NULL| Enim Condimentum PC|([music shops - m...|\n",
      "| 10206519221|          NULL|             NULL|       Fusce Company|[(gift, card, nov...|\n",
      "| 10255988167|          NULL|             NULL|Aliquam Enim Inco...|[(computers, comP...|\n",
      "| 10264435225|          NULL|             NULL|    Ipsum Primis Ltd|[[watch, clock, a...|\n",
      "| 10279061213|          NULL|             NULL|Pede Ultrices Ind...|([computer progra...|\n",
      "| 10323485998|          NULL|             NULL|           Nunc Inc.|[(furniture, home...|\n",
      "+------------+--------------+-----------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merchant_table = merchant_fraud.join(tbl_merchants, on=\"merchant_abn\", how=\"right\")\n",
    "merchant_table.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4073"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all string to lowercase\n",
    "merchant_table = merchant_table.withColumn(\"name\", lower(col(\"name\"))) \\\n",
    "                               .withColumn(\"tags\", lower(col(\"tags\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all brackets to []\n",
    "\n",
    "# replace '(' with '['\n",
    "merchant_table = merchant_table.withColumn(\"tags_converted\", regexp_replace(col(\"tags\"), r'\\(', '['))\n",
    "\n",
    "# replace ')' with ']'\n",
    "merchant_table = merchant_table.withColumn(\"tags_converted\", regexp_replace(col(\"tags_converted\"), r'\\)', ']'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>order_datetime</th><th>fraud_probability</th><th>name</th><th>category</th><th>revenue level</th><th>take_rate</th></tr>\n",
       "<tr><td>10023283211</td><td>NULL</td><td>NULL</td><td>felis limited</td><td>furniture, home f...</td><td>e</td><td>0.18</td></tr>\n",
       "<tr><td>10142254217</td><td>NULL</td><td>NULL</td><td>arcu ac orci corp...</td><td>cable, satellite,...</td><td>b</td><td>4.22</td></tr>\n",
       "<tr><td>10165489824</td><td>NULL</td><td>NULL</td><td>nunc sed company</td><td>jewelry, watch, c...</td><td>b</td><td>4.40</td></tr>\n",
       "<tr><td>10187291046</td><td>NULL</td><td>NULL</td><td>ultricies digniss...</td><td>watch, clock, and...</td><td>b</td><td>3.29</td></tr>\n",
       "<tr><td>10192359162</td><td>NULL</td><td>NULL</td><td>enim condimentum pc</td><td>music shops - mus...</td><td>a</td><td>6.33</td></tr>\n",
       "<tr><td>10206519221</td><td>NULL</td><td>NULL</td><td>fusce company</td><td>gift, card, novel...</td><td>a</td><td>6.34</td></tr>\n",
       "<tr><td>10255988167</td><td>NULL</td><td>NULL</td><td>aliquam enim inco...</td><td>computers, comput...</td><td>b</td><td>4.32</td></tr>\n",
       "<tr><td>10264435225</td><td>NULL</td><td>NULL</td><td>ipsum primis ltd</td><td>watch, clock, and...</td><td>c</td><td>2.39</td></tr>\n",
       "<tr><td>10279061213</td><td>NULL</td><td>NULL</td><td>pede ultrices ind...</td><td>computer programm...</td><td>a</td><td>5.71</td></tr>\n",
       "<tr><td>10323485998</td><td>NULL</td><td>NULL</td><td>nunc inc.</td><td>furniture, home f...</td><td>a</td><td>6.61</td></tr>\n",
       "<tr><td>10342410215</td><td>NULL</td><td>NULL</td><td>facilisis facilis...</td><td>computers, comput...</td><td>a</td><td>6.34</td></tr>\n",
       "<tr><td>10346855916</td><td>NULL</td><td>NULL</td><td>odio institute</td><td>equipment, tool, ...</td><td>b</td><td>3.57</td></tr>\n",
       "<tr><td>10364012396</td><td>NULL</td><td>NULL</td><td>rutrum justo ltd</td><td>music shops - mus...</td><td>b</td><td>3.63</td></tr>\n",
       "<tr><td>10385011947</td><td>NULL</td><td>NULL</td><td>tellus foundation</td><td>artist supply and...</td><td>b</td><td>3.17</td></tr>\n",
       "<tr><td>10385163239</td><td>NULL</td><td>NULL</td><td>sed et company</td><td>florists supplies...</td><td>a</td><td>6.61</td></tr>\n",
       "<tr><td>10385250025</td><td>NULL</td><td>NULL</td><td>id ltd</td><td>computers, comput...</td><td>a</td><td>5.54</td></tr>\n",
       "<tr><td>10404542215</td><td>NULL</td><td>NULL</td><td>consequat foundation</td><td>antique shops - s...</td><td>a</td><td>6.93</td></tr>\n",
       "<tr><td>10430380319</td><td>NULL</td><td>NULL</td><td>sit amet nulla corp.</td><td>motor vehicle sup...</td><td>b</td><td>4.97</td></tr>\n",
       "<tr><td>10441711491</td><td>NULL</td><td>NULL</td><td>massa vestibulum ...</td><td>motor vehicle sup...</td><td>a</td><td>5.77</td></tr>\n",
       "<tr><td>10462560289</td><td>NULL</td><td>NULL</td><td>ut consulting</td><td>gift, card, novel...</td><td>c</td><td>2.95</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------+--------------+-----------------+--------------------+--------------------+-------------+---------+\n",
       "|merchant_abn|order_datetime|fraud_probability|                name|            category|revenue level|take_rate|\n",
       "+------------+--------------+-----------------+--------------------+--------------------+-------------+---------+\n",
       "| 10023283211|          NULL|             NULL|       felis limited|furniture, home f...|            e|     0.18|\n",
       "| 10142254217|          NULL|             NULL|arcu ac orci corp...|cable, satellite,...|            b|     4.22|\n",
       "| 10165489824|          NULL|             NULL|    nunc sed company|jewelry, watch, c...|            b|     4.40|\n",
       "| 10187291046|          NULL|             NULL|ultricies digniss...|watch, clock, and...|            b|     3.29|\n",
       "| 10192359162|          NULL|             NULL| enim condimentum pc|music shops - mus...|            a|     6.33|\n",
       "| 10206519221|          NULL|             NULL|       fusce company|gift, card, novel...|            a|     6.34|\n",
       "| 10255988167|          NULL|             NULL|aliquam enim inco...|computers, comput...|            b|     4.32|\n",
       "| 10264435225|          NULL|             NULL|    ipsum primis ltd|watch, clock, and...|            c|     2.39|\n",
       "| 10279061213|          NULL|             NULL|pede ultrices ind...|computer programm...|            a|     5.71|\n",
       "| 10323485998|          NULL|             NULL|           nunc inc.|furniture, home f...|            a|     6.61|\n",
       "| 10342410215|          NULL|             NULL|facilisis facilis...|computers, comput...|            a|     6.34|\n",
       "| 10346855916|          NULL|             NULL|      odio institute|equipment, tool, ...|            b|     3.57|\n",
       "| 10364012396|          NULL|             NULL|    rutrum justo ltd|music shops - mus...|            b|     3.63|\n",
       "| 10385011947|          NULL|             NULL|   tellus foundation|artist supply and...|            b|     3.17|\n",
       "| 10385163239|          NULL|             NULL|      sed et company|florists supplies...|            a|     6.61|\n",
       "| 10385250025|          NULL|             NULL|              id ltd|computers, comput...|            a|     5.54|\n",
       "| 10404542215|          NULL|             NULL|consequat foundation|antique shops - s...|            a|     6.93|\n",
       "| 10430380319|          NULL|             NULL|sit amet nulla corp.|motor vehicle sup...|            b|     4.97|\n",
       "| 10441711491|          NULL|             NULL|massa vestibulum ...|motor vehicle sup...|            a|     5.77|\n",
       "| 10462560289|          NULL|             NULL|       ut consulting|gift, card, novel...|            c|     2.95|\n",
       "+------------+--------------+-----------------+--------------------+--------------------+-------------+---------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the elements by '], [' to get the three parts\n",
    "split_col = split(col(\"tags_converted\"), r'\\], \\[')\n",
    "\n",
    "# clean up each part and assign them to separate columns\n",
    "merchant_table = merchant_table.withColumn(\"category\", trim(regexp_replace(split_col.getItem(0), r'^\\[|\\]$', ''))) \\\n",
    "                               .withColumn(\"revenue level\", trim(regexp_replace(split_col.getItem(1), r'^\\[|\\]$', ''))) \\\n",
    "                               .withColumn(\"take_rate\", trim(regexp_replace(split_col.getItem(2), r'^\\[take rate: |\\]$', '')))\n",
    "\n",
    "# keep only numeric values\n",
    "merchant_table = merchant_table.withColumn(\"category\", regexp_replace(col(\"category\"), r'^\\[|\\]$', ''))\n",
    "merchant_table = merchant_table.withColumn(\"take_rate\", regexp_replace(col(\"take_rate\"), r'[^\\d.]+', ''))\n",
    "\n",
    "merchant_table.drop('tags', 'tags_converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----------------+----+----+--------------+--------+-------------+---------+\n",
      "|merchant_abn|order_datetime|fraud_probability|name|tags|tags_converted|category|revenue level|take_rate|\n",
      "+------------+--------------+-----------------+----+----+--------------+--------+-------------+---------+\n",
      "+------------+--------------+-----------------+----+----+--------------+--------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for invalid fraud probabilities - none\n",
    "invalid_fraud_prob = merchant_table.filter((col(\"fraud_probability\") < 0) | (col(\"fraud_probability\") > 100))\n",
    "invalid_fraud_prob.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the 'merchant_abn' column.\n",
      "There are 3978 missing values in the 'order_datetime' column.\n",
      "There are 3978 missing values in the 'fraud_probability' column.\n",
      "There are 0 missing values in the 'name' column.\n",
      "There are 0 missing values in the 'tags' column.\n",
      "There are 0 missing values in the 'tags_converted' column.\n",
      "There are 0 missing values in the 'category' column.\n",
      "There are 0 missing values in the 'revenue level' column.\n",
      "There are 0 missing values in the 'take_rate' column.\n"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "# all columns in the DataFrame\n",
    "columns = merchant_table.columns\n",
    "\n",
    "# count missing values for each column\n",
    "missing_values_expr = [sum(col(c).isNull().cast(\"int\")).alias(c) for c in columns]\n",
    "missing_counts = merchant_table.select(*missing_values_expr).collect()[0].asDict()\n",
    "\n",
    "# missing values count for each column\n",
    "for column, count in missing_counts.items():\n",
    "    print(f\"There are {count} missing values in the '{column}' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4026"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_table.select('merchant_abn').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame as a Parquet file\n",
    "merchant_table.write.parquet('../data/curated/merchant', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_fraud = spark.read.csv('../data/tables/tables 1/consumer_fraud_probability.csv', header=True, inferSchema=True)\n",
    "consumer_user_details = spark.read.parquet('../data/tables/tables 1/consumer_user_details.parquet')\n",
    "tbl_consumer = spark.read.csv('../data/tables/tables 1/tbl_consumer.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "|            name|             address|state|postcode|gender|consumer_id|\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "|Yolanda Williams|413 Haney Gardens...|   WA|    6935|Female|    1195503|\n",
      "|      Mary Smith|     3764 Amber Oval|  NSW|    2782|Female|     179208|\n",
      "|   Jill Jones MD|  40693 Henry Greens|   NT|     862|Female|    1194530|\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split tbl_consumer table\n",
    "# single column into multiple columns\n",
    "split_col = split(tbl_consumer['name|address|state|postcode|gender|consumer_id'], r'\\|')\n",
    "\n",
    "# create separate columns for each part\n",
    "tbl_consumer = tbl_consumer.withColumn('name', split_col.getItem(0)) \\\n",
    "                           .withColumn('address', split_col.getItem(1)) \\\n",
    "                           .withColumn('state', split_col.getItem(2)) \\\n",
    "                           .withColumn('postcode', split_col.getItem(3)) \\\n",
    "                           .withColumn('gender', split_col.getItem(4)) \\\n",
    "                           .withColumn('consumer_id', split_col.getItem(5))\n",
    "\n",
    "tbl_consumer = tbl_consumer.drop('name|address|state|postcode|gender|consumer_id')\n",
    "\n",
    "tbl_consumer.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20128\n",
      "499999\n",
      "499999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499999"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(consumer_fraud.select('user_id').distinct().count())\n",
    "print(consumer_user_details.select('user_id').distinct().count())\n",
    "print(consumer_user_details.select('consumer_id').distinct().count())\n",
    "tbl_consumer.select('consumer_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join cosumer tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499999"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_table = consumer_fraud.join(consumer_user_details, on=\"user_id\", how=\"right\")\n",
    "consumer_table.select('user_id').distinct().count()\n",
    "consumer_table = consumer_table.join(tbl_consumer, on=\"consumer_id\", how=\"inner\")\n",
    "consumer_table.select('consumer_id').distinct().count()\n",
    "# consumer_table.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer table preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------+-----------------+----+-------+-----+--------+------+\n",
      "|consumer_id|user_id|order_datetime|fraud_probability|name|address|state|postcode|gender|\n",
      "+-----------+-------+--------------+-----------------+----+-------+-----+--------+------+\n",
      "+-----------+-------+--------------+-----------------+----+-------+-----+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for invalid fraud probabilities - none\n",
    "invalid_fraud_prob = consumer_table.filter((col(\"fraud_probability\") < 0) | (col(\"fraud_probability\") > 100))\n",
    "invalid_fraud_prob.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the 'consumer_id' column.\n",
      "There are 0 missing values in the 'user_id' column.\n",
      "There are 479871 missing values in the 'order_datetime' column.\n",
      "There are 479871 missing values in the 'fraud_probability' column.\n",
      "There are 0 missing values in the 'name' column.\n",
      "There are 0 missing values in the 'address' column.\n",
      "There are 0 missing values in the 'state' column.\n",
      "There are 0 missing values in the 'postcode' column.\n",
      "There are 0 missing values in the 'gender' column.\n"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "# all columns in the DataFrame\n",
    "columns = consumer_table.columns\n",
    "\n",
    "# count missing values for each column\n",
    "missing_values_expr = [sum(col(c).isNull().cast(\"int\")).alias(c) for c in columns]\n",
    "missing_counts = consumer_table.select(*missing_values_expr).collect()[0].asDict()\n",
    "\n",
    "# missing values count for each column\n",
    "for column, count in missing_counts.items():\n",
    "    print(f\"There are {count} missing values in the '{column}' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a Parquet file\n",
    "consumer_table.write.parquet('../data/curated/consumer', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2 3 4 - transaction tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 transactions tables\n",
    "tables_2 = spark.read.parquet('../data/tables/tables 2')\n",
    "tables_3 = spark.read.parquet('../data/tables/tables 3')\n",
    "tables_4 = spark.read.parquet('../data/tables/tables 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions in table 2 3 4:  3643266 4508106 6044133\n"
     ]
    }
   ],
   "source": [
    "print('number of transactions in table 2 3 4: ', tables_2.count(), tables_3.count(), tables_4.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all transactions - 14195505 transactions with no duplicate record\n",
    "transaction_table = tables_2.union(tables_3).union(tables_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------------+--------------------+--------------+\n",
      "|user_id|merchant_abn|      dollar_value|            order_id|order_datetime|\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "|  18478| 62191208634|63.255848959735246|949a63c8-29f7-4ab...|    2021-08-20|\n",
      "|      2| 15549624934| 130.3505283105634|6a84c3cf-612a-457...|    2021-08-20|\n",
      "|  18479| 64403598239|120.15860593212783|b10dcc33-e53f-425...|    2021-08-20|\n",
      "|      3| 60956456424| 136.6785200286976|0f09c5a5-784e-447...|    2021-08-20|\n",
      "|  18479| 94493496784| 72.96316578355305|f6c78c1a-4600-4c5...|    2021-08-20|\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------+--------+--------------+-----+\n",
      "|user_id|merchant_abn|dollar_value|order_id|order_datetime|count|\n",
      "+-------+------------+------------+--------+--------------+-----+\n",
      "+-------+------------+------------+--------+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check duplicate transaction records\n",
    "\n",
    "# group by all columns and count occurrences\n",
    "duplicates = transaction_table.groupBy(transaction_table.columns).count()\n",
    "\n",
    "# keep only duplicate records\n",
    "duplicates = duplicates.filter(col(\"count\") > 1)\n",
    "\n",
    "# duplicate row\n",
    "duplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1522:===================================>                 (24 + 12) / 36]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the 'user_id' column.\n",
      "There are 0 missing values in the 'merchant_abn' column.\n",
      "There are 0 missing values in the 'dollar_value' column.\n",
      "There are 0 missing values in the 'order_id' column.\n",
      "There are 0 missing values in the 'order_datetime' column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "# all columns in the DataFrame\n",
    "columns = transaction_table.columns\n",
    "\n",
    "# count missing values for each column\n",
    "missing_values_expr = [sum(col(c).isNull().cast(\"int\")).alias(c) for c in columns]\n",
    "missing_counts = transaction_table.select(*missing_values_expr).collect()[0].asDict()\n",
    "\n",
    "# missing values count for each column\n",
    "for column, count in missing_counts.items():\n",
    "    print(f\"There are {count} missing values in the '{column}' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the DataFrame as a Parquet file\n",
    "transaction_table.write.parquet('../data/curated/transaction', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location datasets (Suburb and postcode)\n",
    "1. https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\n",
    "2. https://data.gov.au/data/dataset/6cd8989d-4aca-46b7-b93e-77befcffa0b6/resource/cb659d81-5bd2-41f5-a3d0-67257c9a5893/download/asgs2021codingindexs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SA2 name and its geometry\n",
    "gda = gpd.read_file('../data/tables/SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp')\n",
    "gda = gda[['SA2_NAME21', 'geometry']]\n",
    "\n",
    "# read the SA2 name and postcode lookup table \n",
    "postcode_sa2 = pd.read_csv('../data/tables/asgs2021codingindexs/2023 Locality to 2021 SA2 Coding Index.csv')\n",
    "postcode_sa2 = postcode_sa2[['SA2_NAME_2021', 'POSTCODE', 'STATE']]\n",
    "postcode_sa2 = postcode_sa2.dropna(subset=['POSTCODE'])\n",
    "postcode_sa2['POSTCODE'] = postcode_sa2['POSTCODE'].astype(int)\n",
    "postcode_sa2 = postcode_sa2.rename(columns={'POSTCODE': 'postcode'})\n",
    "postcode_sa2 = postcode_sa2.rename(columns={'STATE': 'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_NAME21</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braidwood</td>\n",
       "      <td>POLYGON ((149.58424 -35.44426, 149.58444 -35.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karabar</td>\n",
       "      <td>POLYGON ((149.21899 -35.36738, 149.218 -35.366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>POLYGON ((149.21326 -35.34325, 149.21619 -35.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queanbeyan - East</td>\n",
       "      <td>POLYGON ((149.24034 -35.34781, 149.24024 -35.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queanbeyan West - Jerrabomberra</td>\n",
       "      <td>POLYGON ((149.19572 -35.36126, 149.1997 -35.35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        SA2_NAME21  \\\n",
       "0                        Braidwood   \n",
       "1                          Karabar   \n",
       "2                       Queanbeyan   \n",
       "3                Queanbeyan - East   \n",
       "4  Queanbeyan West - Jerrabomberra   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((149.58424 -35.44426, 149.58444 -35.4...  \n",
       "1  POLYGON ((149.21899 -35.36738, 149.218 -35.366...  \n",
       "2  POLYGON ((149.21326 -35.34325, 149.21619 -35.3...  \n",
       "3  POLYGON ((149.24034 -35.34781, 149.24024 -35.3...  \n",
       "4  POLYGON ((149.19572 -35.36126, 149.1997 -35.35...  "
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_NAME_2021</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Mountain</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parkes (ACT) - South</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barton</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deakin</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parkes (ACT) - South</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SA2_NAME_2021  postcode state\n",
       "0        Black Mountain      2600   ACT\n",
       "1  Parkes (ACT) - South      2600   ACT\n",
       "2                Barton      2600   ACT\n",
       "3                Deakin      2600   ACT\n",
       "4  Parkes (ACT) - South      2600   ACT"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcode_sa2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2 name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braidwood</td>\n",
       "      <td>POLYGON ((149.58424 -35.44426, 149.58444 -35.4...</td>\n",
       "      <td>2580</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Braidwood</td>\n",
       "      <td>POLYGON ((149.58424 -35.44426, 149.58444 -35.4...</td>\n",
       "      <td>2622</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Karabar</td>\n",
       "      <td>POLYGON ((149.21899 -35.36738, 149.218 -35.366...</td>\n",
       "      <td>2620</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>POLYGON ((149.21326 -35.34325, 149.21619 -35.3...</td>\n",
       "      <td>2620</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>POLYGON ((149.21326 -35.34325, 149.21619 -35.3...</td>\n",
       "      <td>2620</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SA2 name                                           geometry  postcode  \\\n",
       "0    Braidwood  POLYGON ((149.58424 -35.44426, 149.58444 -35.4...      2580   \n",
       "5    Braidwood  POLYGON ((149.58424 -35.44426, 149.58444 -35.4...      2622   \n",
       "53     Karabar  POLYGON ((149.21899 -35.36738, 149.218 -35.366...      2620   \n",
       "56  Queanbeyan  POLYGON ((149.21326 -35.34325, 149.21619 -35.3...      2620   \n",
       "57  Queanbeyan  POLYGON ((149.21326 -35.34325, 149.21619 -35.3...      2620   \n",
       "\n",
       "   state  \n",
       "0    NSW  \n",
       "5    NSW  \n",
       "53   NSW  \n",
       "56   ACT  \n",
       "57   NSW  "
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcode_sa2_geo = gda.merge(postcode_sa2, left_on='SA2_NAME21', right_on='SA2_NAME_2021', how='inner')\n",
    "postcode_sa2_geo = postcode_sa2_geo.drop_duplicates()\n",
    "postcode_sa2_geo = postcode_sa2_geo.drop(columns=['SA2_NAME_2021'])\n",
    "postcode_sa2_geo = postcode_sa2_geo.rename(columns={\n",
    "    'SA2_NAME21': 'SA2 name'\n",
    "})\n",
    "postcode_sa2_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique postcodes: 2643\n"
     ]
    }
   ],
   "source": [
    "# number of unique postcode\n",
    "unique_postcodes_count = len(postcode_sa2_geo['postcode'].unique())\n",
    "print(f\"Number of unique postcodes: {unique_postcodes_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4841, 4)"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcode_sa2_geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "postcode_sa2_geo.to_file('../data/curated/postcode_sa2_geo.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income dataset\n",
    "https://www.abs.gov.au/statistics/labour/earnings-and-working-conditions/personal-income-australia/2020-21-financial-year/Table%201%20-%20Total%20income%2C%20earners%20and%20summary%20statistics%20by%20geography%2C%202016-17%20to%202020-21.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total income dataset\n",
    "# read the fourth Excel sheet\n",
    "income_pandas = pd.read_excel('../data/tables/Table 1 - Total income, earners and summary statistics by geography, 2016-17 to 2020-21.xlsx', sheet_name=4, header=[5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----------+\n",
      "|            SA2 name|earners|     income|\n",
      "+--------------------+-------+-----------+\n",
      "|           Braidwood|  2,467|169,986,703|\n",
      "|             Karabar|  5,103|355,538,349|\n",
      "|          Queanbeyan|  7,028|486,157,371|\n",
      "|   Queanbeyan - East|  3,398|252,003,459|\n",
      "|Queanbeyan West -...|  8,422|774,662,009|\n",
      "|             Googong|  3,555|331,654,182|\n",
      "|Queanbeyan Surrounds| 10,647|923,249,146|\n",
      "|             Bombala|  1,399| 80,343,596|\n",
      "|               Cooma|  3,752|227,153,809|\n",
      "|     Cooma Surrounds|  2,045|122,806,651|\n",
      "|Jindabyne - Berri...|  4,652|287,143,356|\n",
      "|        Batemans Bay|  4,314|204,396,825|\n",
      "|Batemans Bay - South|  4,773|256,006,252|\n",
      "|       Bega - Tathra|  5,086|282,411,339|\n",
      "|Bega-Eden Hinterland|  5,499|258,027,869|\n",
      "|   Broulee - Tomakin|  2,200|132,283,166|\n",
      "|   Deua - Wadbilliga|     15|    881,592|\n",
      "|                Eden|  1,792| 89,113,914|\n",
      "|Eurobodalla Hinte...|  2,029|103,578,656|\n",
      "|Merimbula - Tura ...|  6,694|365,742,677|\n",
      "+--------------------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# column of interest\n",
    "columns_of_interest = [\n",
    "    ('Unnamed: 1_level_0', 'SA2 NAME'),\n",
    "    ('Earners (persons)', '2020-21'),\n",
    "    ('Sum ($)',  '2020-21')\n",
    "]\n",
    "income_pandas = income_pandas.loc[:, columns_of_interest]\n",
    "\n",
    "# rename the columns\n",
    "income_pandas.columns = ['SA2 name', 'earners', 'income']\n",
    "\n",
    "# remove the specific row with NaNs\n",
    "income_pandas = income_pandas[income_pandas.notna().all(axis=1)]\n",
    "\n",
    "# reset the index to maintain a clean index\n",
    "income_pandas = income_pandas.reset_index(drop=True)\n",
    "\n",
    "# convert Pandas DataFrame to Spark DataFrame\n",
    "income_pyspark = spark.createDataFrame(income_pandas)\n",
    "income_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame as a Parquet file\n",
    "income_pyspark.write.parquet('../data/curated/income', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population dataset\n",
    "https://www.abs.gov.au/statistics/people/population/regional-population/2021-22/32180DS0003_2001-22r.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th>Unnamed: 1_level_0</th>\n",
       "      <th>Unnamed: 2_level_0</th>\n",
       "      <th>Unnamed: 3_level_0</th>\n",
       "      <th>Unnamed: 4_level_0</th>\n",
       "      <th>Unnamed: 5_level_0</th>\n",
       "      <th>Unnamed: 6_level_0</th>\n",
       "      <th>Unnamed: 7_level_0</th>\n",
       "      <th>Unnamed: 8_level_0</th>\n",
       "      <th>Unnamed: 9_level_0</th>\n",
       "      <th>...</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>S/T code</th>\n",
       "      <th>S/T name</th>\n",
       "      <th>GCCSA code</th>\n",
       "      <th>GCCSA name</th>\n",
       "      <th>SA4 code</th>\n",
       "      <th>SA4 name</th>\n",
       "      <th>SA3 code</th>\n",
       "      <th>SA3 name</th>\n",
       "      <th>SA2 code</th>\n",
       "      <th>SA2 name</th>\n",
       "      <th>...</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Capital Region</td>\n",
       "      <td>10102.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>101021007.0</td>\n",
       "      <td>Braidwood</td>\n",
       "      <td>...</td>\n",
       "      <td>3685</td>\n",
       "      <td>3762</td>\n",
       "      <td>3849</td>\n",
       "      <td>3950.0</td>\n",
       "      <td>4041.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>4218.0</td>\n",
       "      <td>4282.0</td>\n",
       "      <td>4332.0</td>\n",
       "      <td>4366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Capital Region</td>\n",
       "      <td>10102.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>101021008.0</td>\n",
       "      <td>Karabar</td>\n",
       "      <td>...</td>\n",
       "      <td>8848</td>\n",
       "      <td>8731</td>\n",
       "      <td>8603</td>\n",
       "      <td>8531.0</td>\n",
       "      <td>8530.0</td>\n",
       "      <td>8516.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>8535.0</td>\n",
       "      <td>8548.0</td>\n",
       "      <td>8528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Capital Region</td>\n",
       "      <td>10102.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>101021009.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>...</td>\n",
       "      <td>11050</td>\n",
       "      <td>11199</td>\n",
       "      <td>11213</td>\n",
       "      <td>11230.0</td>\n",
       "      <td>11362.0</td>\n",
       "      <td>11460.0</td>\n",
       "      <td>11468.0</td>\n",
       "      <td>11460.0</td>\n",
       "      <td>11375.0</td>\n",
       "      <td>11390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Capital Region</td>\n",
       "      <td>10102.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>101021010.0</td>\n",
       "      <td>Queanbeyan - East</td>\n",
       "      <td>...</td>\n",
       "      <td>4983</td>\n",
       "      <td>4967</td>\n",
       "      <td>4961</td>\n",
       "      <td>4970.0</td>\n",
       "      <td>5016.0</td>\n",
       "      <td>5079.0</td>\n",
       "      <td>5126.0</td>\n",
       "      <td>5089.0</td>\n",
       "      <td>5097.0</td>\n",
       "      <td>5090.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0_level_0 Unnamed: 1_level_0 Unnamed: 2_level_0 Unnamed: 3_level_0  \\\n",
       "            S/T code           S/T name         GCCSA code         GCCSA name   \n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                  1    New South Wales               12.0        Rest of NSW   \n",
       "2                  1    New South Wales               12.0        Rest of NSW   \n",
       "3                  1    New South Wales               12.0        Rest of NSW   \n",
       "4                  1    New South Wales               12.0        Rest of NSW   \n",
       "\n",
       "  Unnamed: 4_level_0 Unnamed: 5_level_0 Unnamed: 6_level_0 Unnamed: 7_level_0  \\\n",
       "            SA4 code           SA4 name           SA3 code           SA3 name   \n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1              101.0     Capital Region            10102.0         Queanbeyan   \n",
       "2              101.0     Capital Region            10102.0         Queanbeyan   \n",
       "3              101.0     Capital Region            10102.0         Queanbeyan   \n",
       "4              101.0     Capital Region            10102.0         Queanbeyan   \n",
       "\n",
       "  Unnamed: 8_level_0 Unnamed: 9_level_0  ...   2013   2014   2015     2016  \\\n",
       "            SA2 code           SA2 name  ...    no.    no.    no.      no.   \n",
       "0                NaN                NaN  ...    NaN    NaN    NaN      NaN   \n",
       "1        101021007.0          Braidwood  ...   3685   3762   3849   3950.0   \n",
       "2        101021008.0            Karabar  ...   8848   8731   8603   8531.0   \n",
       "3        101021009.0         Queanbeyan  ...  11050  11199  11213  11230.0   \n",
       "4        101021010.0  Queanbeyan - East  ...   4983   4967   4961   4970.0   \n",
       "\n",
       "      2017     2018     2019     2020     2021     2022  \n",
       "       no.      no.      no.      no.      no.      no.  \n",
       "0      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "1   4041.0   4145.0   4218.0   4282.0   4332.0   4366.0  \n",
       "2   8530.0   8516.0   8500.0   8535.0   8548.0   8528.0  \n",
       "3  11362.0  11460.0  11468.0  11460.0  11375.0  11390.0  \n",
       "4   5016.0   5079.0   5126.0   5089.0   5097.0   5090.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the first Excel sheet\n",
    "population_pandas = pd.read_excel('../data/tables/32180DS0003_2001-22r.xlsx', sheet_name=1, header=[6, 7])\n",
    "population_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('Unnamed: 0_level_0',   'S/T code'),\n",
      "            ('Unnamed: 1_level_0',   'S/T name'),\n",
      "            ('Unnamed: 2_level_0', 'GCCSA code'),\n",
      "            ('Unnamed: 3_level_0', 'GCCSA name'),\n",
      "            ('Unnamed: 4_level_0',   'SA4 code'),\n",
      "            ('Unnamed: 5_level_0',   'SA4 name'),\n",
      "            ('Unnamed: 6_level_0',   'SA3 code'),\n",
      "            ('Unnamed: 7_level_0',   'SA3 name'),\n",
      "            ('Unnamed: 8_level_0',   'SA2 code'),\n",
      "            ('Unnamed: 9_level_0',   'SA2 name'),\n",
      "            (                2001,        'no.'),\n",
      "            (                2002,        'no.'),\n",
      "            (                2003,        'no.'),\n",
      "            (                2004,        'no.'),\n",
      "            (                2005,        'no.'),\n",
      "            (                2006,        'no.'),\n",
      "            (                2007,        'no.'),\n",
      "            (                2008,        'no.'),\n",
      "            (                2009,        'no.'),\n",
      "            (                2010,        'no.'),\n",
      "            (                2011,        'no.'),\n",
      "            (                2012,        'no.'),\n",
      "            (                2013,        'no.'),\n",
      "            (                2014,        'no.'),\n",
      "            (                2015,        'no.'),\n",
      "            (                2016,        'no.'),\n",
      "            (                2017,        'no.'),\n",
      "            (                2018,        'no.'),\n",
      "            (                2019,        'no.'),\n",
      "            (                2020,        'no.'),\n",
      "            (                2021,        'no.'),\n",
      "            (                2022,        'no.')],\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(population_pandas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing the NaN row:\n",
      "            SA2 name     2021     2022\n",
      "0                NaN      NaN      NaN\n",
      "1          Braidwood   4332.0   4366.0\n",
      "2            Karabar   8548.0   8528.0\n",
      "3         Queanbeyan  11375.0  11390.0\n",
      "4  Queanbeyan - East   5097.0   5090.0\n",
      "After removing the NaN row:\n",
      "                          SA2 name     2021     2022\n",
      "0                        Braidwood   4332.0   4366.0\n",
      "1                          Karabar   8548.0   8528.0\n",
      "2                       Queanbeyan  11375.0  11390.0\n",
      "3                Queanbeyan - East   5097.0   5090.0\n",
      "4  Queanbeyan West - Jerrabomberra  12748.0  12779.0\n"
     ]
    }
   ],
   "source": [
    "# columns of interest\n",
    "columns_of_interest = [\n",
    "    ('Unnamed: 9_level_0', 'SA2 name'),\n",
    "    (2021, 'no.'),\n",
    "    (2022, 'no.')\n",
    "]\n",
    "\n",
    "# selected columns\n",
    "population_selected = population_pandas.loc[:, columns_of_interest]\n",
    "\n",
    "# rename the columns\n",
    "population_selected.columns = ['SA2 name', '2021', '2022']\n",
    "\n",
    "# selected columns before removing the row\n",
    "print(\"Before removing the NaN row:\")\n",
    "print(population_selected.head())\n",
    "\n",
    "# remove the specific row with NaNs\n",
    "population_selected_cleaned = population_selected[population_selected.notna().all(axis=1)]\n",
    "\n",
    "# reset the index to maintain a clean index\n",
    "population_selected_cleaned = population_selected_cleaned.reset_index(drop=True)\n",
    "\n",
    "print(\"After removing the NaN row:\")\n",
    "print(population_selected_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2 name</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braidwood</td>\n",
       "      <td>4332.0</td>\n",
       "      <td>4366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karabar</td>\n",
       "      <td>8548.0</td>\n",
       "      <td>8528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>11375.0</td>\n",
       "      <td>11390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queanbeyan - East</td>\n",
       "      <td>5097.0</td>\n",
       "      <td>5090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queanbeyan West - Jerrabomberra</td>\n",
       "      <td>12748.0</td>\n",
       "      <td>12779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>Christmas Island</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>Cocos (Keeling) Islands</td>\n",
       "      <td>603.0</td>\n",
       "      <td>614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>Jervis Bay</td>\n",
       "      <td>309.0</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>2221.0</td>\n",
       "      <td>2213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>TOTAL AUSTRALIA</td>\n",
       "      <td>25685412.0</td>\n",
       "      <td>26005540.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2455 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SA2 name        2021        2022\n",
       "0                           Braidwood      4332.0      4366.0\n",
       "1                             Karabar      8548.0      8528.0\n",
       "2                          Queanbeyan     11375.0     11390.0\n",
       "3                   Queanbeyan - East      5097.0      5090.0\n",
       "4     Queanbeyan West - Jerrabomberra     12748.0     12779.0\n",
       "...                               ...         ...         ...\n",
       "2450                 Christmas Island      1717.0      1787.0\n",
       "2451          Cocos (Keeling) Islands       603.0       614.0\n",
       "2452                       Jervis Bay       309.0       311.0\n",
       "2453                   Norfolk Island      2221.0      2213.0\n",
       "2454                  TOTAL AUSTRALIA  25685412.0  26005540.0\n",
       "\n",
       "[2455 rows x 3 columns]"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_selected_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values summary:\n",
      "SA2 name    0\n",
      "2021        0\n",
      "2022        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remaining NaN values\n",
    "missing_value = population_selected_cleaned.isna().sum()\n",
    "print(\"NaN values summary:\")\n",
    "print(missing_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after averaging population of 2021 and 2022:\n",
      "                             SA2 name  average_population\n",
      "0                           Braidwood              4349.0\n",
      "1                             Karabar              8538.0\n",
      "2                          Queanbeyan             11382.5\n",
      "3                   Queanbeyan - East              5093.5\n",
      "4     Queanbeyan West - Jerrabomberra             12763.5\n",
      "...                               ...                 ...\n",
      "2450                 Christmas Island              1752.0\n",
      "2451          Cocos (Keeling) Islands               608.5\n",
      "2452                       Jervis Bay               310.0\n",
      "2453                   Norfolk Island              2217.0\n",
      "2454                  TOTAL AUSTRALIA          25845476.0\n",
      "\n",
      "[2455 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# check if '2021' and '2022' columns are present\n",
    "if '2021' in population_selected_cleaned.columns and '2022' in population_selected_cleaned.columns:\n",
    "    \n",
    "    # create a new column 'average_population' that averages the '2021' and '2022' columns\n",
    "    population_selected_cleaned['average_population'] = population_selected_cleaned[['2021', '2022']].mean(axis=1)\n",
    "    \n",
    "    # drop the '2021' and '2022' columns\n",
    "    population_selected_cleaned = population_selected_cleaned.drop(columns=['2021', '2022'])\n",
    "    \n",
    "else:\n",
    "    print(\"The columns '2021' and '2022' are not present in the DataFrame.\")\n",
    "\n",
    "# dataFrame with the average column\n",
    "print(\"DataFrame after averaging population of 2021 and 2022:\")\n",
    "print(population_selected_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            SA2 name|average_population|\n",
      "+--------------------+------------------+\n",
      "|           Braidwood|            4349.0|\n",
      "|             Karabar|            8538.0|\n",
      "|          Queanbeyan|           11382.5|\n",
      "|   Queanbeyan - East|            5093.5|\n",
      "|Queanbeyan West -...|           12763.5|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert Pandas DataFrame to Spark DataFrame\n",
    "population = spark.createDataFrame(population_selected_cleaned)\n",
    "population.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a Parquet file\n",
    "population.write.parquet('../data/curated/population', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment dataset\n",
    "https://explore.data.abs.gov.au/vis?tm=unemployment%20sa2&pg=0&df[ds]=C21_ASGS&df[id]=C21_G43_SA2&df[ag]=ABS&df[vs]=1.0.0&pd=2021%2C&dq=LFS_P1.3...&ly[rs]=REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATAFLOW</th>\n",
       "      <th>LFEMP: Selected Labour Force/Education/Migration characteristic</th>\n",
       "      <th>SEXP: Sex</th>\n",
       "      <th>REGION: Region</th>\n",
       "      <th>REGION_TYPE: Region Type</th>\n",
       "      <th>STATE: State</th>\n",
       "      <th>TIME_PERIOD: Time Period</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>101021611: Queanbeyan Surrounds</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>1: New South Wales</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>107011134: Unanderra - Mount Kembla</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>1: New South Wales</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>204031069: Bright - Mount Beauty</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>2: Victoria</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>211051280: Montrose</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>2: Victoria</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>213051468: Werribee - West</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>2: Victoria</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATAFLOW  \\\n",
       "0  ABS:C21_G43_SA2(1.0.0)   \n",
       "1  ABS:C21_G43_SA2(1.0.0)   \n",
       "2  ABS:C21_G43_SA2(1.0.0)   \n",
       "3  ABS:C21_G43_SA2(1.0.0)   \n",
       "4  ABS:C21_G43_SA2(1.0.0)   \n",
       "\n",
       "  LFEMP: Selected Labour Force/Education/Migration characteristic   SEXP: Sex  \\\n",
       "0        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "1        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "2        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "3        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "4        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "\n",
       "                        REGION: Region       REGION_TYPE: Region Type  \\\n",
       "0      101021611: Queanbeyan Surrounds  SA2: Statistical Area Level 2   \n",
       "1  107011134: Unanderra - Mount Kembla  SA2: Statistical Area Level 2   \n",
       "2     204031069: Bright - Mount Beauty  SA2: Statistical Area Level 2   \n",
       "3                  211051280: Montrose  SA2: Statistical Area Level 2   \n",
       "4           213051468: Werribee - West  SA2: Statistical Area Level 2   \n",
       "\n",
       "         STATE: State  TIME_PERIOD: Time Period  OBS_VALUE  \n",
       "0  1: New South Wales                      2021        2.6  \n",
       "1  1: New South Wales                      2021        4.2  \n",
       "2         2: Victoria                      2021        1.8  \n",
       "3         2: Victoria                      2021        3.1  \n",
       "4         2: Victoria                      2021        6.2  "
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the CSV file\n",
    "unemployment = pd.read_csv('../data/tables/ABS_C21_G43_SA2_1.0.0_LFS_P1.3....csv')\n",
    "unemployment.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              SA2 name  unemployment_rate\n",
      "0      101021611: Queanbeyan Surrounds                2.6\n",
      "1  107011134: Unanderra - Mount Kembla                4.2\n",
      "2     204031069: Bright - Mount Beauty                1.8\n",
      "3                  211051280: Montrose                3.1\n",
      "4           213051468: Werribee - West                6.2\n"
     ]
    }
   ],
   "source": [
    "# select the columns 'REGION' and 'obs_value'\n",
    "selected_columns = unemployment[['REGION: Region', 'OBS_VALUE']]\n",
    "\n",
    "# select and rename the columns\n",
    "selected_columns = unemployment[['REGION: Region', 'OBS_VALUE']]\n",
    "selected_columns.columns = ['SA2 name', 'unemployment_rate']\n",
    "\n",
    "# selected columns\n",
    "print(selected_columns.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   SA2 name  unemployment_rate\n",
      "0      Queanbeyan Surrounds                2.6\n",
      "1  Unanderra - Mount Kembla                4.2\n",
      "2     Bright - Mount Beauty                1.8\n",
      "3                  Montrose                3.1\n",
      "4           Werribee - West                6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/0_8y1ngj2zx7c7x2zn44jf1r0000gn/T/ipykernel_5820/2321517987.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_columns.loc[:, 'SA2 name'] = selected_columns['SA2 name'].str.replace(r'^\\d+:\\s*', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# remove numbers and colon from the 'SA2 name' column\n",
    "selected_columns.loc[:, 'SA2 name'] = selected_columns['SA2 name'].str.replace(r'^\\d+:\\s*', '', regex=True)\n",
    "\n",
    "# display the DataFrame with the cleaned 'SA2 name'\n",
    "print(selected_columns.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            SA2 name|unemployment_rate|\n",
      "+--------------------+-----------------+\n",
      "|Queanbeyan Surrounds|              2.6|\n",
      "|Unanderra - Mount...|              4.2|\n",
      "|Bright - Mount Be...|              1.8|\n",
      "|            Montrose|              3.1|\n",
      "|     Werribee - West|              6.2|\n",
      "+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert Pandas DataFrame to Spark DataFrame\n",
    "unemployment = spark.createDataFrame(selected_columns)\n",
    "unemployment.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame as a Parquet file\n",
    "unemployment.write.parquet('../data/curated/unemployment', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge income and population\n",
    "df_income_pop = population.join(income_pyspark, on='SA2 name', how='inner')\n",
    "\n",
    "# merge the above with unemployment rate\n",
    "df_income_pop_unemp = df_income_pop.join(unemployment, on='SA2 name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_income_pop_unemp_pandas = df_income_pop_unemp.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_pop_unemp_post = pd.merge(df_income_pop_unemp_pandas, postcode_sa2_geo, on='SA2 name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_pop_unemp_post = df_income_pop_unemp_post.drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2 name</th>\n",
       "      <th>average_population</th>\n",
       "      <th>earners</th>\n",
       "      <th>income</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kiama Downs - Minnamurra</td>\n",
       "      <td>6002.0</td>\n",
       "      <td>3,633</td>\n",
       "      <td>255,198,601</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2533</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raymond Terrace</td>\n",
       "      <td>14802.0</td>\n",
       "      <td>7,118</td>\n",
       "      <td>390,229,618</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2322</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raymond Terrace</td>\n",
       "      <td>14802.0</td>\n",
       "      <td>7,118</td>\n",
       "      <td>390,229,618</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2324</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Niagara Park - Lisarow</td>\n",
       "      <td>8215.5</td>\n",
       "      <td>4,877</td>\n",
       "      <td>315,596,744</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2250</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wellington</td>\n",
       "      <td>8932.5</td>\n",
       "      <td>3,993</td>\n",
       "      <td>201,898,931</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2818</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SA2 name  average_population earners       income  \\\n",
       "0  Kiama Downs - Minnamurra              6002.0   3,633  255,198,601   \n",
       "1           Raymond Terrace             14802.0   7,118  390,229,618   \n",
       "2           Raymond Terrace             14802.0   7,118  390,229,618   \n",
       "3    Niagara Park - Lisarow              8215.5   4,877  315,596,744   \n",
       "4                Wellington              8932.5   3,993  201,898,931   \n",
       "\n",
       "   unemployment_rate  postcode state  \n",
       "0                3.2      2533   NSW  \n",
       "1                7.2      2322   NSW  \n",
       "2                7.2      2324   NSW  \n",
       "3                3.9      2250   NSW  \n",
       "4                6.0      2818   NSW  "
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_income_pop_unemp_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the DataFrame as a Parquet file\n",
    "df_income_pop_unemp_post = spark.createDataFrame(df_income_pop_unemp_post)\n",
    "# save the DataFrame as a Parquet file\n",
    "df_income_pop_unemp_post.write.parquet('../data/curated/merged_datasets', mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
