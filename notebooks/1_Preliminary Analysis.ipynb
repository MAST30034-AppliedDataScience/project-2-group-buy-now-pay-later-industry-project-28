{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNPL Data timeline: 2021-2-28 to 2022-10-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import* \n",
    "from pyspark.sql.functions import regexp_replace, col, trim, split\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/07 01:47:30 WARN Utils: Your hostname, Cocos-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 172.16.33.67 instead (on interface en0)\n",
      "24/09/07 01:47:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/07 01:47:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/07 01:47:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Preliminary Analysis\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.driver.memory\",\"4G\")\n",
    "    .config(\"spark.executor.memory\",\"4G\")\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNPL dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merchant datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fraud = spark.read.csv('../data/tables/tables 1/merchant_fraud_probability.csv', header=True, inferSchema=True)\n",
    "tbl_merchants = spark.read.parquet('../data/tables/tables 1/tbl_merchants.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4026"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(merchant_fraud.select('merchant_abn').distinct().count())\n",
    "tbl_merchants.select('merchant_abn').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Merchant datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----------------+--------------------+--------------------+\n",
      "|merchant_abn|order_datetime|fraud_probability|                name|                tags|\n",
      "+------------+--------------+-----------------+--------------------+--------------------+\n",
      "| 10023283211|          NULL|             NULL|       Felis Limited|((furniture, home...|\n",
      "| 10142254217|          NULL|             NULL|Arcu Ac Orci Corp...|([cable, satellit...|\n",
      "| 10165489824|          NULL|             NULL|    Nunc Sed Company|([jewelry, watch,...|\n",
      "| 10187291046|          NULL|             NULL|Ultricies Digniss...|([wAtch, clock, a...|\n",
      "| 10192359162|          NULL|             NULL| Enim Condimentum PC|([music shops - m...|\n",
      "| 10206519221|          NULL|             NULL|       Fusce Company|[(gift, card, nov...|\n",
      "| 10255988167|          NULL|             NULL|Aliquam Enim Inco...|[(computers, comP...|\n",
      "| 10264435225|          NULL|             NULL|    Ipsum Primis Ltd|[[watch, clock, a...|\n",
      "| 10279061213|          NULL|             NULL|Pede Ultrices Ind...|([computer progra...|\n",
      "| 10323485998|          NULL|             NULL|           Nunc Inc.|[(furniture, home...|\n",
      "+------------+--------------+-----------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merchant_table = merchant_fraud.join(tbl_merchants, on=\"merchant_abn\", how=\"right\")\n",
    "merchant_table.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4073"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all string to lowercase\n",
    "merchant_table = merchant_table.withColumn(\"name\", lower(col(\"name\"))) \\\n",
    "                               .withColumn(\"tags\", lower(col(\"tags\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all brackets to []\n",
    "\n",
    "# replace '(' with '['\n",
    "merchant_table = merchant_table.withColumn(\"tags_converted\", regexp_replace(col(\"tags\"), r'\\(', '['))\n",
    "\n",
    "# replace ')' with ']'\n",
    "merchant_table = merchant_table.withColumn(\"tags_converted\", regexp_replace(col(\"tags_converted\"), \n",
    "                                                                            r'\\)', ']'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>order_datetime</th><th>fraud_probability</th><th>name</th><th>category</th><th>revenue level</th><th>take_rate</th></tr>\n",
       "<tr><td>10023283211</td><td>NULL</td><td>NULL</td><td>felis limited</td><td>furniture, home f...</td><td>e</td><td>0.18</td></tr>\n",
       "<tr><td>10142254217</td><td>NULL</td><td>NULL</td><td>arcu ac orci corp...</td><td>cable, satellite,...</td><td>b</td><td>4.22</td></tr>\n",
       "<tr><td>10165489824</td><td>NULL</td><td>NULL</td><td>nunc sed company</td><td>jewelry, watch, c...</td><td>b</td><td>4.40</td></tr>\n",
       "<tr><td>10187291046</td><td>NULL</td><td>NULL</td><td>ultricies digniss...</td><td>watch, clock, and...</td><td>b</td><td>3.29</td></tr>\n",
       "<tr><td>10192359162</td><td>NULL</td><td>NULL</td><td>enim condimentum pc</td><td>music shops - mus...</td><td>a</td><td>6.33</td></tr>\n",
       "<tr><td>10206519221</td><td>NULL</td><td>NULL</td><td>fusce company</td><td>gift, card, novel...</td><td>a</td><td>6.34</td></tr>\n",
       "<tr><td>10255988167</td><td>NULL</td><td>NULL</td><td>aliquam enim inco...</td><td>computers, comput...</td><td>b</td><td>4.32</td></tr>\n",
       "<tr><td>10264435225</td><td>NULL</td><td>NULL</td><td>ipsum primis ltd</td><td>watch, clock, and...</td><td>c</td><td>2.39</td></tr>\n",
       "<tr><td>10279061213</td><td>NULL</td><td>NULL</td><td>pede ultrices ind...</td><td>computer programm...</td><td>a</td><td>5.71</td></tr>\n",
       "<tr><td>10323485998</td><td>NULL</td><td>NULL</td><td>nunc inc.</td><td>furniture, home f...</td><td>a</td><td>6.61</td></tr>\n",
       "<tr><td>10342410215</td><td>NULL</td><td>NULL</td><td>facilisis facilis...</td><td>computers, comput...</td><td>a</td><td>6.34</td></tr>\n",
       "<tr><td>10346855916</td><td>NULL</td><td>NULL</td><td>odio institute</td><td>equipment, tool, ...</td><td>b</td><td>3.57</td></tr>\n",
       "<tr><td>10364012396</td><td>NULL</td><td>NULL</td><td>rutrum justo ltd</td><td>music shops - mus...</td><td>b</td><td>3.63</td></tr>\n",
       "<tr><td>10385011947</td><td>NULL</td><td>NULL</td><td>tellus foundation</td><td>artist supply and...</td><td>b</td><td>3.17</td></tr>\n",
       "<tr><td>10385163239</td><td>NULL</td><td>NULL</td><td>sed et company</td><td>florists supplies...</td><td>a</td><td>6.61</td></tr>\n",
       "<tr><td>10385250025</td><td>NULL</td><td>NULL</td><td>id ltd</td><td>computers, comput...</td><td>a</td><td>5.54</td></tr>\n",
       "<tr><td>10404542215</td><td>NULL</td><td>NULL</td><td>consequat foundation</td><td>antique shops - s...</td><td>a</td><td>6.93</td></tr>\n",
       "<tr><td>10430380319</td><td>NULL</td><td>NULL</td><td>sit amet nulla corp.</td><td>motor vehicle sup...</td><td>b</td><td>4.97</td></tr>\n",
       "<tr><td>10441711491</td><td>NULL</td><td>NULL</td><td>massa vestibulum ...</td><td>motor vehicle sup...</td><td>a</td><td>5.77</td></tr>\n",
       "<tr><td>10462560289</td><td>NULL</td><td>NULL</td><td>ut consulting</td><td>gift, card, novel...</td><td>c</td><td>2.95</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------+--------------+-----------------+--------------------+--------------------+-------------+---------+\n",
       "|merchant_abn|order_datetime|fraud_probability|                name|            category|revenue level|take_rate|\n",
       "+------------+--------------+-----------------+--------------------+--------------------+-------------+---------+\n",
       "| 10023283211|          NULL|             NULL|       felis limited|furniture, home f...|            e|     0.18|\n",
       "| 10142254217|          NULL|             NULL|arcu ac orci corp...|cable, satellite,...|            b|     4.22|\n",
       "| 10165489824|          NULL|             NULL|    nunc sed company|jewelry, watch, c...|            b|     4.40|\n",
       "| 10187291046|          NULL|             NULL|ultricies digniss...|watch, clock, and...|            b|     3.29|\n",
       "| 10192359162|          NULL|             NULL| enim condimentum pc|music shops - mus...|            a|     6.33|\n",
       "| 10206519221|          NULL|             NULL|       fusce company|gift, card, novel...|            a|     6.34|\n",
       "| 10255988167|          NULL|             NULL|aliquam enim inco...|computers, comput...|            b|     4.32|\n",
       "| 10264435225|          NULL|             NULL|    ipsum primis ltd|watch, clock, and...|            c|     2.39|\n",
       "| 10279061213|          NULL|             NULL|pede ultrices ind...|computer programm...|            a|     5.71|\n",
       "| 10323485998|          NULL|             NULL|           nunc inc.|furniture, home f...|            a|     6.61|\n",
       "| 10342410215|          NULL|             NULL|facilisis facilis...|computers, comput...|            a|     6.34|\n",
       "| 10346855916|          NULL|             NULL|      odio institute|equipment, tool, ...|            b|     3.57|\n",
       "| 10364012396|          NULL|             NULL|    rutrum justo ltd|music shops - mus...|            b|     3.63|\n",
       "| 10385011947|          NULL|             NULL|   tellus foundation|artist supply and...|            b|     3.17|\n",
       "| 10385163239|          NULL|             NULL|      sed et company|florists supplies...|            a|     6.61|\n",
       "| 10385250025|          NULL|             NULL|              id ltd|computers, comput...|            a|     5.54|\n",
       "| 10404542215|          NULL|             NULL|consequat foundation|antique shops - s...|            a|     6.93|\n",
       "| 10430380319|          NULL|             NULL|sit amet nulla corp.|motor vehicle sup...|            b|     4.97|\n",
       "| 10441711491|          NULL|             NULL|massa vestibulum ...|motor vehicle sup...|            a|     5.77|\n",
       "| 10462560289|          NULL|             NULL|       ut consulting|gift, card, novel...|            c|     2.95|\n",
       "+------------+--------------+-----------------+--------------------+--------------------+-------------+---------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the elements by '], [' to get the three parts\n",
    "split_col = split(col(\"tags_converted\"), r'\\], \\[')\n",
    "\n",
    "# clean up each part and assign them to separate columns\n",
    "merchant_table = merchant_table.withColumn(\"category\", trim(regexp_replace(split_col.getItem(0), r'^\\[|\\]$', ''))) \\\n",
    "                               .withColumn(\"revenue level\", trim(regexp_replace(split_col.getItem(1), r'^\\[|\\]$', ''))) \\\n",
    "                               .withColumn(\"take_rate\", trim(regexp_replace(split_col.getItem(2), r'^\\[take rate: |\\]$', '')))\n",
    "\n",
    "# keep only numeric values\n",
    "merchant_table = merchant_table.withColumn(\"category\", regexp_replace(col(\"category\"), r'^\\[|\\]$', ''))\n",
    "merchant_table = merchant_table.withColumn(\"take_rate\", regexp_replace(col(\"take_rate\"), r'[^\\d.]+', ''))\n",
    "\n",
    "merchant_table.drop('tags', 'tags_converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----------------+----+----+--------------+--------+-------------+---------+\n",
      "|merchant_abn|order_datetime|fraud_probability|name|tags|tags_converted|category|revenue level|take_rate|\n",
      "+------------+--------------+-----------------+----+----+--------------+--------+-------------+---------+\n",
      "+------------+--------------+-----------------+----+----+--------------+--------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for invalid fraud probabilities - none\n",
    "invalid_fraud_prob = merchant_table.filter((col(\"fraud_probability\") < 0) | (col(\"fraud_probability\") > 100))\n",
    "invalid_fraud_prob.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the 'merchant_abn' column.\n",
      "There are 3978 missing values in the 'order_datetime' column.\n",
      "There are 3978 missing values in the 'fraud_probability' column.\n",
      "There are 0 missing values in the 'name' column.\n",
      "There are 0 missing values in the 'tags' column.\n",
      "There are 0 missing values in the 'tags_converted' column.\n",
      "There are 0 missing values in the 'category' column.\n",
      "There are 0 missing values in the 'revenue level' column.\n",
      "There are 0 missing values in the 'take_rate' column.\n"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "# all columns in the DataFrame\n",
    "columns = merchant_table.columns\n",
    "\n",
    "# count missing values for each column\n",
    "missing_values_expr = [sum(col(c).isNull().cast(\"int\")).alias(c) for c in columns]\n",
    "missing_counts = merchant_table.select(*missing_values_expr).collect()[0].asDict()\n",
    "\n",
    "# missing values count for each column\n",
    "for column, count in missing_counts.items():\n",
    "    print(f\"There are {count} missing values in the '{column}' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_table.select('merchant_abn').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame as a Parquet file\n",
    "merchant_table.write.parquet('../data/curated/merchant', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumer datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_fraud = spark.read.csv('../data/tables/tables 1/consumer_fraud_probability.csv', header=True, inferSchema=True)\n",
    "consumer_user_details = spark.read.parquet('../data/tables/tables 1/consumer_user_details.parquet')\n",
    "tbl_consumer = spark.read.csv('../data/tables/tables 1/tbl_consumer.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "|            name|             address|state|postcode|gender|consumer_id|\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "|Yolanda Williams|413 Haney Gardens...|   WA|    6935|Female|    1195503|\n",
      "|      Mary Smith|     3764 Amber Oval|  NSW|    2782|Female|     179208|\n",
      "|   Jill Jones MD|  40693 Henry Greens|   NT|     862|Female|    1194530|\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split tbl_consumer table\n",
    "# single column into multiple columns\n",
    "split_col = split(tbl_consumer['name|address|state|postcode|gender|consumer_id'], r'\\|')\n",
    "\n",
    "# create separate columns for each part\n",
    "tbl_consumer = tbl_consumer.withColumn('name', split_col.getItem(0)) \\\n",
    "                           .withColumn('address', split_col.getItem(1)) \\\n",
    "                           .withColumn('state', split_col.getItem(2)) \\\n",
    "                           .withColumn('postcode', split_col.getItem(3)) \\\n",
    "                           .withColumn('gender', split_col.getItem(4)) \\\n",
    "                           .withColumn('consumer_id', split_col.getItem(5))\n",
    "\n",
    "tbl_consumer = tbl_consumer.drop('name|address|state|postcode|gender|consumer_id')\n",
    "\n",
    "tbl_consumer.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20128\n",
      "499999\n",
      "499999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(consumer_fraud.select('user_id').distinct().count())\n",
    "print(consumer_user_details.select('user_id').distinct().count())\n",
    "print(consumer_user_details.select('consumer_id').distinct().count())\n",
    "tbl_consumer.select('consumer_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join cosumer tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_table = consumer_fraud.join(consumer_user_details, on=\"user_id\", how=\"right\")\n",
    "consumer_table.select('user_id').distinct().count()\n",
    "consumer_table = consumer_table.join(tbl_consumer, on=\"consumer_id\", how=\"inner\")\n",
    "consumer_table.select('consumer_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:==>               (1 + 7) / 8][Stage 86:>                 (0 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------+-----------------+---------------+--------------------+-----+--------+-----------+\n",
      "|consumer_id|user_id|order_datetime|fraud_probability|           name|             address|state|postcode|     gender|\n",
      "+-----------+-------+--------------+-----------------+---------------+--------------------+-----+--------+-----------+\n",
      "|          7| 371406|          NULL|             NULL| James Williams|     3709 Mary River|  TAS|    7248|       Male|\n",
      "|         19|  92127|          NULL|             NULL| Dennis Ramirez|20761 Matthews Vi...|  QLD|    4406|       Male|\n",
      "|         22| 166164|          NULL|             NULL|  Joseph Turner|    4305 White Walks|  NSW|    2281|       Male|\n",
      "|         26| 476081|          NULL|             NULL|  Chloe Walters|   04666 Castro Hill|  VIC|    3026|     Female|\n",
      "|         29| 286075|          NULL|             NULL|      Evan Pope|  1121 Sims Causeway|  QLD|    4706|Undisclosed|\n",
      "|         54| 352250|          NULL|             NULL|  Rebecca Lyons|306 Amber Islands...|  QLD|    4516|     Female|\n",
      "|         77|  37181|          NULL|             NULL| Donald Burgess|52479 Joseph Centers|   WA|    6017|       Male|\n",
      "|         94|  77872|          NULL|             NULL|Nicholas Davila|    69458 Smith Fort|  QLD|    4754|       Male|\n",
      "|        110| 166747|          NULL|             NULL|       John Cox|75252 Mitchell La...|  NSW|    2778|       Male|\n",
      "|        149|  59264|          NULL|             NULL|      Adam Ward|42217 Scott Viadu...|  NSW|    2397|       Male|\n",
      "+-----------+-------+--------------+-----------------+---------------+--------------------+-----+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "consumer_table.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer table preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------+-----------------+----+-------+-----+--------+------+\n",
      "|consumer_id|user_id|order_datetime|fraud_probability|name|address|state|postcode|gender|\n",
      "+-----------+-------+--------------+-----------------+----+-------+-----+--------+------+\n",
      "+-----------+-------+--------------+-----------------+----+-------+-----+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check for invalid fraud probabilities - none\n",
    "invalid_fraud_prob = consumer_table.filter((col(\"fraud_probability\") < 0) | (col(\"fraud_probability\") > 100))\n",
    "invalid_fraud_prob.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the 'consumer_id' column.\n",
      "There are 0 missing values in the 'user_id' column.\n",
      "There are 479871 missing values in the 'order_datetime' column.\n",
      "There are 479871 missing values in the 'fraud_probability' column.\n",
      "There are 0 missing values in the 'name' column.\n",
      "There are 0 missing values in the 'address' column.\n",
      "There are 0 missing values in the 'state' column.\n",
      "There are 0 missing values in the 'postcode' column.\n",
      "There are 0 missing values in the 'gender' column.\n"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "# all columns in the DataFrame\n",
    "columns = consumer_table.columns\n",
    "\n",
    "# count missing values for each column\n",
    "missing_values_expr = [sum(col(c).isNull().cast(\"int\")).alias(c) for c in columns]\n",
    "missing_counts = consumer_table.select(*missing_values_expr).collect()[0].asDict()\n",
    "\n",
    "# missing values count for each column\n",
    "for column, count in missing_counts.items():\n",
    "    print(f\"There are {count} missing values in the '{column}' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame as a Parquet file\n",
    "consumer_table.write.parquet('../data/curated/consumer', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2 3 4 - transaction tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 transactions tables\n",
    "tables_2 = spark.read.parquet('../data/tables/tables 2')\n",
    "tables_3 = spark.read.parquet('../data/tables/tables 3')\n",
    "tables_4 = spark.read.parquet('../data/tables/tables 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions in table 2 3 4:  3643266 4508106 6044133\n"
     ]
    }
   ],
   "source": [
    "print('number of transactions in table 2 3 4: ', tables_2.count(), tables_3.count(), tables_4.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all transactions - 14195505 transactions with no duplicate record\n",
    "transaction_table = tables_2.union(tables_3).union(tables_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------------+--------------------+--------------+\n",
      "|user_id|merchant_abn|      dollar_value|            order_id|order_datetime|\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "|  18478| 62191208634|63.255848959735246|949a63c8-29f7-4ab...|    2021-08-20|\n",
      "|      2| 15549624934| 130.3505283105634|6a84c3cf-612a-457...|    2021-08-20|\n",
      "|  18479| 64403598239|120.15860593212783|b10dcc33-e53f-425...|    2021-08-20|\n",
      "|      3| 60956456424| 136.6785200286976|0f09c5a5-784e-447...|    2021-08-20|\n",
      "|  18479| 94493496784| 72.96316578355305|f6c78c1a-4600-4c5...|    2021-08-20|\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 130:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------+--------+--------------+-----+\n",
      "|user_id|merchant_abn|dollar_value|order_id|order_datetime|count|\n",
      "+-------+------------+------------+--------+--------------+-----+\n",
      "+-------+------------+------------+--------+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check duplicate transaction records\n",
    "\n",
    "# group by all columns and count occurrences\n",
    "duplicates = transaction_table.groupBy(transaction_table.columns).count()\n",
    "\n",
    "# keep only duplicate records\n",
    "duplicates = duplicates.filter(col(\"count\") > 1)\n",
    "\n",
    "# duplicate row\n",
    "duplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:=================================>                     (16 + 8) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in the 'user_id' column.\n",
      "There are 0 missing values in the 'merchant_abn' column.\n",
      "There are 0 missing values in the 'dollar_value' column.\n",
      "There are 0 missing values in the 'order_id' column.\n",
      "There are 0 missing values in the 'order_datetime' column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "# all columns in the DataFrame\n",
    "columns = transaction_table.columns\n",
    "\n",
    "# count missing values for each column\n",
    "missing_values_expr = [sum(col(c).isNull().cast(\"int\")).alias(c) for c in columns]\n",
    "missing_counts = transaction_table.select(*missing_values_expr).collect()[0].asDict()\n",
    "\n",
    "# missing values count for each column\n",
    "for column, count in missing_counts.items():\n",
    "    print(f\"There are {count} missing values in the '{column}' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the DataFrame as a Parquet file\n",
    "transaction_table.write.parquet('../data/curated/transaction', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location datasets (Suburb and postcode)\n",
    "1. https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\n",
    "2. https://data.gov.au/data/dataset/6cd8989d-4aca-46b7-b93e-77befcffa0b6/resource/cb659d81-5bd2-41f5-a3d0-67257c9a5893/download/asgs2021codingindexs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SA2 name and its geometry\n",
    "gda = gpd.read_file('../data/tables/SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp')\n",
    "gda = gda[['SA2_NAME21', 'geometry']]\n",
    "\n",
    "# read the SA2 name and postcode lookup table \n",
    "postcode_sa2 = pd.read_csv('../data/tables/asgs2021codingindexs/2023 Locality to 2021 SA2 Coding Index.csv')\n",
    "postcode_sa2 = postcode_sa2[['SA2_NAME_2021', 'POSTCODE', 'STATE']]\n",
    "postcode_sa2 = postcode_sa2.dropna(subset=['POSTCODE'])\n",
    "postcode_sa2['POSTCODE'] = postcode_sa2['POSTCODE'].astype(int)\n",
    "postcode_sa2 = postcode_sa2.rename(columns={'POSTCODE': 'postcode'})\n",
    "postcode_sa2 = postcode_sa2.rename(columns={'STATE': 'state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_NAME21</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braidwood</td>\n",
       "      <td>POLYGON ((149.58424 -35.44426, 149.58444 -35.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karabar</td>\n",
       "      <td>POLYGON ((149.21899 -35.36738, 149.218 -35.366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>POLYGON ((149.21326 -35.34325, 149.21619 -35.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queanbeyan - East</td>\n",
       "      <td>POLYGON ((149.24034 -35.34781, 149.24024 -35.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queanbeyan West - Jerrabomberra</td>\n",
       "      <td>POLYGON ((149.19572 -35.36126, 149.1997 -35.35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        SA2_NAME21  \\\n",
       "0                        Braidwood   \n",
       "1                          Karabar   \n",
       "2                       Queanbeyan   \n",
       "3                Queanbeyan - East   \n",
       "4  Queanbeyan West - Jerrabomberra   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((149.58424 -35.44426, 149.58444 -35.4...  \n",
       "1  POLYGON ((149.21899 -35.36738, 149.218 -35.366...  \n",
       "2  POLYGON ((149.21326 -35.34325, 149.21619 -35.3...  \n",
       "3  POLYGON ((149.24034 -35.34781, 149.24024 -35.3...  \n",
       "4  POLYGON ((149.19572 -35.36126, 149.1997 -35.35...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_NAME_2021</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Mountain</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parkes (ACT) - South</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barton</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deakin</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parkes (ACT) - South</td>\n",
       "      <td>2600</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SA2_NAME_2021  postcode state\n",
       "0        Black Mountain      2600   ACT\n",
       "1  Parkes (ACT) - South      2600   ACT\n",
       "2                Barton      2600   ACT\n",
       "3                Deakin      2600   ACT\n",
       "4  Parkes (ACT) - South      2600   ACT"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcode_sa2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braidwood</td>\n",
       "      <td>POLYGON ((149.58424 -35.44426, 149.58444 -35.4...</td>\n",
       "      <td>2580</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Braidwood</td>\n",
       "      <td>POLYGON ((149.58424 -35.44426, 149.58444 -35.4...</td>\n",
       "      <td>2622</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Karabar</td>\n",
       "      <td>POLYGON ((149.21899 -35.36738, 149.218 -35.366...</td>\n",
       "      <td>2620</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>POLYGON ((149.21326 -35.34325, 149.21619 -35.3...</td>\n",
       "      <td>2620</td>\n",
       "      <td>ACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>POLYGON ((149.21326 -35.34325, 149.21619 -35.3...</td>\n",
       "      <td>2620</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SA2_name                                           geometry  postcode  \\\n",
       "0    Braidwood  POLYGON ((149.58424 -35.44426, 149.58444 -35.4...      2580   \n",
       "5    Braidwood  POLYGON ((149.58424 -35.44426, 149.58444 -35.4...      2622   \n",
       "53     Karabar  POLYGON ((149.21899 -35.36738, 149.218 -35.366...      2620   \n",
       "56  Queanbeyan  POLYGON ((149.21326 -35.34325, 149.21619 -35.3...      2620   \n",
       "57  Queanbeyan  POLYGON ((149.21326 -35.34325, 149.21619 -35.3...      2620   \n",
       "\n",
       "   state  \n",
       "0    NSW  \n",
       "5    NSW  \n",
       "53   NSW  \n",
       "56   ACT  \n",
       "57   NSW  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcode_sa2_geo = gda.merge(postcode_sa2, left_on='SA2_NAME21', right_on='SA2_NAME_2021', how='inner')\n",
    "postcode_sa2_geo = postcode_sa2_geo.drop_duplicates()\n",
    "postcode_sa2_geo = postcode_sa2_geo.drop(columns=['SA2_NAME_2021'])\n",
    "postcode_sa2_geo = postcode_sa2_geo.rename(columns={'SA2_NAME21': 'SA2_name'})\n",
    "postcode_sa2_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postcode_sa2_geo:\n",
      "SA2_name      object\n",
      "geometry    geometry\n",
      "postcode       int64\n",
      "state         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check the data type\n",
    "print('postcode_sa2_geo:')\n",
    "print(postcode_sa2_geo.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique postcodes: 2643\n"
     ]
    }
   ],
   "source": [
    "# number of unique postcode\n",
    "unique_postcodes_count = len(postcode_sa2_geo['postcode'].unique())\n",
    "print(f\"Number of unique postcodes: {unique_postcodes_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4841, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postcode_sa2_geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "postcode_sa2_geo.to_file('../data/curated/postcode_sa2_geo.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income dataset\n",
    "https://www.abs.gov.au/statistics/labour/earnings-and-working-conditions/personal-income-australia/2020-21-financial-year/Table%201%20-%20Total%20income%2C%20earners%20and%20summary%20statistics%20by%20geography%2C%202016-17%20to%202020-21.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total income dataset\n",
    "# read the fourth Excel sheet\n",
    "income_pandas = pd.read_excel('../data/tables/Table 1 - Total income, earners and summary statistics by geography, 2016-17 to 2020-21.xlsx', sheet_name=4, header=[5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----------+\n",
      "|            SA2_name|earners|     income|\n",
      "+--------------------+-------+-----------+\n",
      "|           Braidwood|  2,467|169,986,703|\n",
      "|             Karabar|  5,103|355,538,349|\n",
      "|          Queanbeyan|  7,028|486,157,371|\n",
      "|   Queanbeyan - East|  3,398|252,003,459|\n",
      "|Queanbeyan West -...|  8,422|774,662,009|\n",
      "|             Googong|  3,555|331,654,182|\n",
      "|Queanbeyan Surrounds| 10,647|923,249,146|\n",
      "|             Bombala|  1,399| 80,343,596|\n",
      "|               Cooma|  3,752|227,153,809|\n",
      "|     Cooma Surrounds|  2,045|122,806,651|\n",
      "|Jindabyne - Berri...|  4,652|287,143,356|\n",
      "|        Batemans Bay|  4,314|204,396,825|\n",
      "|Batemans Bay - South|  4,773|256,006,252|\n",
      "|       Bega - Tathra|  5,086|282,411,339|\n",
      "|Bega-Eden Hinterland|  5,499|258,027,869|\n",
      "|   Broulee - Tomakin|  2,200|132,283,166|\n",
      "|   Deua - Wadbilliga|     15|    881,592|\n",
      "|                Eden|  1,792| 89,113,914|\n",
      "|Eurobodalla Hinte...|  2,029|103,578,656|\n",
      "|Merimbula - Tura ...|  6,694|365,742,677|\n",
      "+--------------------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# column of interest\n",
    "columns_of_interest = [\n",
    "    ('Unnamed: 1_level_0', 'SA2 NAME'),\n",
    "    ('Earners (persons)', '2020-21'),\n",
    "    ('Sum ($)',  '2020-21')\n",
    "]\n",
    "income_pandas = income_pandas.loc[:, columns_of_interest]\n",
    "\n",
    "# rename the columns\n",
    "income_pandas.columns = ['SA2_name', 'earners', 'income']\n",
    "\n",
    "# remove the specific row with NaNs\n",
    "income_pandas = income_pandas[income_pandas.notna().all(axis=1)]\n",
    "\n",
    "# reset the index to maintain a clean index\n",
    "income_pandas = income_pandas.reset_index(drop=True)\n",
    "\n",
    "# convert Pandas DataFrame to Spark DataFrame\n",
    "income_pyspark = spark.createDataFrame(income_pandas)\n",
    "income_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame as a Parquet file\n",
    "income_pyspark.write.parquet('../data/curated/income', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population dataset\n",
    "https://www.abs.gov.au/statistics/people/population/regional-population/2021-22/32180DS0003_2001-22r.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th>Unnamed: 1_level_0</th>\n",
       "      <th>Unnamed: 2_level_0</th>\n",
       "      <th>Unnamed: 3_level_0</th>\n",
       "      <th>Unnamed: 4_level_0</th>\n",
       "      <th>Unnamed: 5_level_0</th>\n",
       "      <th>Unnamed: 6_level_0</th>\n",
       "      <th>Unnamed: 7_level_0</th>\n",
       "      <th>Unnamed: 8_level_0</th>\n",
       "      <th>Unnamed: 9_level_0</th>\n",
       "      <th>...</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>S/T code</th>\n",
       "      <th>S/T name</th>\n",
       "      <th>GCCSA code</th>\n",
       "      <th>GCCSA name</th>\n",
       "      <th>SA4 code</th>\n",
       "      <th>SA4 name</th>\n",
       "      <th>SA3 code</th>\n",
       "      <th>SA3 name</th>\n",
       "      <th>SA2 code</th>\n",
       "      <th>SA2 name</th>\n",
       "      <th>...</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "      <th>no.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Capital Region</td>\n",
       "      <td>10102.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>101021007.0</td>\n",
       "      <td>Braidwood</td>\n",
       "      <td>...</td>\n",
       "      <td>3685</td>\n",
       "      <td>3762</td>\n",
       "      <td>3849</td>\n",
       "      <td>3950.0</td>\n",
       "      <td>4041.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>4218.0</td>\n",
       "      <td>4282.0</td>\n",
       "      <td>4332.0</td>\n",
       "      <td>4366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Capital Region</td>\n",
       "      <td>10102.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>101021008.0</td>\n",
       "      <td>Karabar</td>\n",
       "      <td>...</td>\n",
       "      <td>8848</td>\n",
       "      <td>8731</td>\n",
       "      <td>8603</td>\n",
       "      <td>8531.0</td>\n",
       "      <td>8530.0</td>\n",
       "      <td>8516.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>8535.0</td>\n",
       "      <td>8548.0</td>\n",
       "      <td>8528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Capital Region</td>\n",
       "      <td>10102.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>101021009.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>...</td>\n",
       "      <td>11050</td>\n",
       "      <td>11199</td>\n",
       "      <td>11213</td>\n",
       "      <td>11230.0</td>\n",
       "      <td>11362.0</td>\n",
       "      <td>11460.0</td>\n",
       "      <td>11468.0</td>\n",
       "      <td>11460.0</td>\n",
       "      <td>11375.0</td>\n",
       "      <td>11390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Capital Region</td>\n",
       "      <td>10102.0</td>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>101021010.0</td>\n",
       "      <td>Queanbeyan - East</td>\n",
       "      <td>...</td>\n",
       "      <td>4983</td>\n",
       "      <td>4967</td>\n",
       "      <td>4961</td>\n",
       "      <td>4970.0</td>\n",
       "      <td>5016.0</td>\n",
       "      <td>5079.0</td>\n",
       "      <td>5126.0</td>\n",
       "      <td>5089.0</td>\n",
       "      <td>5097.0</td>\n",
       "      <td>5090.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0_level_0 Unnamed: 1_level_0 Unnamed: 2_level_0 Unnamed: 3_level_0  \\\n",
       "            S/T code           S/T name         GCCSA code         GCCSA name   \n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                  1    New South Wales               12.0        Rest of NSW   \n",
       "2                  1    New South Wales               12.0        Rest of NSW   \n",
       "3                  1    New South Wales               12.0        Rest of NSW   \n",
       "4                  1    New South Wales               12.0        Rest of NSW   \n",
       "\n",
       "  Unnamed: 4_level_0 Unnamed: 5_level_0 Unnamed: 6_level_0 Unnamed: 7_level_0  \\\n",
       "            SA4 code           SA4 name           SA3 code           SA3 name   \n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1              101.0     Capital Region            10102.0         Queanbeyan   \n",
       "2              101.0     Capital Region            10102.0         Queanbeyan   \n",
       "3              101.0     Capital Region            10102.0         Queanbeyan   \n",
       "4              101.0     Capital Region            10102.0         Queanbeyan   \n",
       "\n",
       "  Unnamed: 8_level_0 Unnamed: 9_level_0  ...   2013   2014   2015     2016  \\\n",
       "            SA2 code           SA2 name  ...    no.    no.    no.      no.   \n",
       "0                NaN                NaN  ...    NaN    NaN    NaN      NaN   \n",
       "1        101021007.0          Braidwood  ...   3685   3762   3849   3950.0   \n",
       "2        101021008.0            Karabar  ...   8848   8731   8603   8531.0   \n",
       "3        101021009.0         Queanbeyan  ...  11050  11199  11213  11230.0   \n",
       "4        101021010.0  Queanbeyan - East  ...   4983   4967   4961   4970.0   \n",
       "\n",
       "      2017     2018     2019     2020     2021     2022  \n",
       "       no.      no.      no.      no.      no.      no.  \n",
       "0      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "1   4041.0   4145.0   4218.0   4282.0   4332.0   4366.0  \n",
       "2   8530.0   8516.0   8500.0   8535.0   8548.0   8528.0  \n",
       "3  11362.0  11460.0  11468.0  11460.0  11375.0  11390.0  \n",
       "4   5016.0   5079.0   5126.0   5089.0   5097.0   5090.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the first Excel sheet\n",
    "population_pandas = pd.read_excel('../data/tables/32180DS0003_2001-22r.xlsx', sheet_name=1, header=[6, 7])\n",
    "population_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('Unnamed: 0_level_0',   'S/T code'),\n",
      "            ('Unnamed: 1_level_0',   'S/T name'),\n",
      "            ('Unnamed: 2_level_0', 'GCCSA code'),\n",
      "            ('Unnamed: 3_level_0', 'GCCSA name'),\n",
      "            ('Unnamed: 4_level_0',   'SA4 code'),\n",
      "            ('Unnamed: 5_level_0',   'SA4 name'),\n",
      "            ('Unnamed: 6_level_0',   'SA3 code'),\n",
      "            ('Unnamed: 7_level_0',   'SA3 name'),\n",
      "            ('Unnamed: 8_level_0',   'SA2 code'),\n",
      "            ('Unnamed: 9_level_0',   'SA2 name'),\n",
      "            (                2001,        'no.'),\n",
      "            (                2002,        'no.'),\n",
      "            (                2003,        'no.'),\n",
      "            (                2004,        'no.'),\n",
      "            (                2005,        'no.'),\n",
      "            (                2006,        'no.'),\n",
      "            (                2007,        'no.'),\n",
      "            (                2008,        'no.'),\n",
      "            (                2009,        'no.'),\n",
      "            (                2010,        'no.'),\n",
      "            (                2011,        'no.'),\n",
      "            (                2012,        'no.'),\n",
      "            (                2013,        'no.'),\n",
      "            (                2014,        'no.'),\n",
      "            (                2015,        'no.'),\n",
      "            (                2016,        'no.'),\n",
      "            (                2017,        'no.'),\n",
      "            (                2018,        'no.'),\n",
      "            (                2019,        'no.'),\n",
      "            (                2020,        'no.'),\n",
      "            (                2021,        'no.'),\n",
      "            (                2022,        'no.')],\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(population_pandas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing the NaN row:\n",
      "            SA2_name     2021     2022\n",
      "0                NaN      NaN      NaN\n",
      "1          Braidwood   4332.0   4366.0\n",
      "2            Karabar   8548.0   8528.0\n",
      "3         Queanbeyan  11375.0  11390.0\n",
      "4  Queanbeyan - East   5097.0   5090.0\n",
      "After removing the NaN row:\n",
      "                          SA2_name     2021     2022\n",
      "0                        Braidwood   4332.0   4366.0\n",
      "1                          Karabar   8548.0   8528.0\n",
      "2                       Queanbeyan  11375.0  11390.0\n",
      "3                Queanbeyan - East   5097.0   5090.0\n",
      "4  Queanbeyan West - Jerrabomberra  12748.0  12779.0\n"
     ]
    }
   ],
   "source": [
    "# columns of interest\n",
    "columns_of_interest = [\n",
    "    ('Unnamed: 9_level_0', 'SA2 name'),\n",
    "    (2021, 'no.'),\n",
    "    (2022, 'no.')\n",
    "]\n",
    "\n",
    "# selected columns\n",
    "population_selected = population_pandas.loc[:, columns_of_interest]\n",
    "\n",
    "# rename the columns\n",
    "population_selected.columns = ['SA2_name', '2021', '2022']\n",
    "\n",
    "# selected columns before removing the row\n",
    "print(\"Before removing the NaN row:\")\n",
    "print(population_selected.head())\n",
    "\n",
    "# remove the specific row with NaNs\n",
    "population_selected_cleaned = population_selected[population_selected.notna().all(axis=1)]\n",
    "\n",
    "# reset the index to maintain a clean index\n",
    "population_selected_cleaned = population_selected_cleaned.reset_index(drop=True)\n",
    "\n",
    "print(\"After removing the NaN row:\")\n",
    "print(population_selected_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_name</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braidwood</td>\n",
       "      <td>4332.0</td>\n",
       "      <td>4366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karabar</td>\n",
       "      <td>8548.0</td>\n",
       "      <td>8528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queanbeyan</td>\n",
       "      <td>11375.0</td>\n",
       "      <td>11390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queanbeyan - East</td>\n",
       "      <td>5097.0</td>\n",
       "      <td>5090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queanbeyan West - Jerrabomberra</td>\n",
       "      <td>12748.0</td>\n",
       "      <td>12779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>Christmas Island</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>Cocos (Keeling) Islands</td>\n",
       "      <td>603.0</td>\n",
       "      <td>614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>Jervis Bay</td>\n",
       "      <td>309.0</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>Norfolk Island</td>\n",
       "      <td>2221.0</td>\n",
       "      <td>2213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>TOTAL AUSTRALIA</td>\n",
       "      <td>25685412.0</td>\n",
       "      <td>26005540.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2455 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SA2_name        2021        2022\n",
       "0                           Braidwood      4332.0      4366.0\n",
       "1                             Karabar      8548.0      8528.0\n",
       "2                          Queanbeyan     11375.0     11390.0\n",
       "3                   Queanbeyan - East      5097.0      5090.0\n",
       "4     Queanbeyan West - Jerrabomberra     12748.0     12779.0\n",
       "...                               ...         ...         ...\n",
       "2450                 Christmas Island      1717.0      1787.0\n",
       "2451          Cocos (Keeling) Islands       603.0       614.0\n",
       "2452                       Jervis Bay       309.0       311.0\n",
       "2453                   Norfolk Island      2221.0      2213.0\n",
       "2454                  TOTAL AUSTRALIA  25685412.0  26005540.0\n",
       "\n",
       "[2455 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_selected_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values summary:\n",
      "SA2_name    0\n",
      "2021        0\n",
      "2022        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remaining NaN values\n",
    "missing_value = population_selected_cleaned.isna().sum()\n",
    "print(\"NaN values summary:\")\n",
    "print(missing_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after averaging population of 2021 and 2022:\n",
      "                             SA2_name  average_population\n",
      "0                           Braidwood              4349.0\n",
      "1                             Karabar              8538.0\n",
      "2                          Queanbeyan             11382.5\n",
      "3                   Queanbeyan - East              5093.5\n",
      "4     Queanbeyan West - Jerrabomberra             12763.5\n",
      "...                               ...                 ...\n",
      "2450                 Christmas Island              1752.0\n",
      "2451          Cocos (Keeling) Islands               608.5\n",
      "2452                       Jervis Bay               310.0\n",
      "2453                   Norfolk Island              2217.0\n",
      "2454                  TOTAL AUSTRALIA          25845476.0\n",
      "\n",
      "[2455 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# check if '2021' and '2022' columns are present\n",
    "if '2021' in population_selected_cleaned.columns and '2022' in population_selected_cleaned.columns:\n",
    "    \n",
    "    # create a new column 'average_population' that averages the '2021' and '2022' columns\n",
    "    population_selected_cleaned['average_population'] = population_selected_cleaned[['2021', '2022']].mean(axis=1)\n",
    "    \n",
    "    # drop the '2021' and '2022' columns\n",
    "    population_selected_cleaned = population_selected_cleaned.drop(columns=['2021', '2022'])\n",
    "    \n",
    "else:\n",
    "    print(\"The columns '2021' and '2022' are not present in the DataFrame.\")\n",
    "\n",
    "# dataFrame with the average column\n",
    "print(\"DataFrame after averaging population of 2021 and 2022:\")\n",
    "print(population_selected_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            SA2_name|average_population|\n",
      "+--------------------+------------------+\n",
      "|           Braidwood|            4349.0|\n",
      "|             Karabar|            8538.0|\n",
      "|          Queanbeyan|           11382.5|\n",
      "|   Queanbeyan - East|            5093.5|\n",
      "|Queanbeyan West -...|           12763.5|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert Pandas DataFrame to Spark DataFrame\n",
    "population = spark.createDataFrame(population_selected_cleaned)\n",
    "population.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a Parquet file\n",
    "population.write.parquet('../data/curated/population', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment dataset\n",
    "https://explore.data.abs.gov.au/vis?tm=unemployment%20sa2&pg=0&df[ds]=C21_ASGS&df[id]=C21_G43_SA2&df[ag]=ABS&df[vs]=1.0.0&pd=2021%2C&dq=LFS_P1.3...&ly[rs]=REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATAFLOW</th>\n",
       "      <th>LFEMP: Selected Labour Force/Education/Migration characteristic</th>\n",
       "      <th>SEXP: Sex</th>\n",
       "      <th>REGION: Region</th>\n",
       "      <th>REGION_TYPE: Region Type</th>\n",
       "      <th>STATE: State</th>\n",
       "      <th>TIME_PERIOD: Time Period</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>101021611: Queanbeyan Surrounds</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>1: New South Wales</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>107011134: Unanderra - Mount Kembla</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>1: New South Wales</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>204031069: Bright - Mount Beauty</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>2: Victoria</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>211051280: Montrose</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>2: Victoria</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABS:C21_G43_SA2(1.0.0)</td>\n",
       "      <td>LFS_P1: Labour force status: % Unemployment</td>\n",
       "      <td>3: Persons</td>\n",
       "      <td>213051468: Werribee - West</td>\n",
       "      <td>SA2: Statistical Area Level 2</td>\n",
       "      <td>2: Victoria</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATAFLOW  \\\n",
       "0  ABS:C21_G43_SA2(1.0.0)   \n",
       "1  ABS:C21_G43_SA2(1.0.0)   \n",
       "2  ABS:C21_G43_SA2(1.0.0)   \n",
       "3  ABS:C21_G43_SA2(1.0.0)   \n",
       "4  ABS:C21_G43_SA2(1.0.0)   \n",
       "\n",
       "  LFEMP: Selected Labour Force/Education/Migration characteristic   SEXP: Sex  \\\n",
       "0        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "1        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "2        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "3        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "4        LFS_P1: Labour force status: % Unemployment               3: Persons   \n",
       "\n",
       "                        REGION: Region       REGION_TYPE: Region Type  \\\n",
       "0      101021611: Queanbeyan Surrounds  SA2: Statistical Area Level 2   \n",
       "1  107011134: Unanderra - Mount Kembla  SA2: Statistical Area Level 2   \n",
       "2     204031069: Bright - Mount Beauty  SA2: Statistical Area Level 2   \n",
       "3                  211051280: Montrose  SA2: Statistical Area Level 2   \n",
       "4           213051468: Werribee - West  SA2: Statistical Area Level 2   \n",
       "\n",
       "         STATE: State  TIME_PERIOD: Time Period  OBS_VALUE  \n",
       "0  1: New South Wales                      2021        2.6  \n",
       "1  1: New South Wales                      2021        4.2  \n",
       "2         2: Victoria                      2021        1.8  \n",
       "3         2: Victoria                      2021        3.1  \n",
       "4         2: Victoria                      2021        6.2  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the CSV file\n",
    "unemployment = pd.read_csv('../data/tables/ABS_C21_G43_SA2_1.0.0_LFS_P1.3....csv')\n",
    "unemployment.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              SA2_name  unemployment_rate\n",
      "0      101021611: Queanbeyan Surrounds                2.6\n",
      "1  107011134: Unanderra - Mount Kembla                4.2\n",
      "2     204031069: Bright - Mount Beauty                1.8\n",
      "3                  211051280: Montrose                3.1\n",
      "4           213051468: Werribee - West                6.2\n"
     ]
    }
   ],
   "source": [
    "# select the columns 'REGION' and 'obs_value'\n",
    "selected_columns = unemployment[['REGION: Region', 'OBS_VALUE']]\n",
    "\n",
    "# select and rename the columns\n",
    "selected_columns = unemployment[['REGION: Region', 'OBS_VALUE']]\n",
    "selected_columns.columns = ['SA2_name', 'unemployment_rate']\n",
    "\n",
    "# selected columns\n",
    "print(selected_columns.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   SA2_name  unemployment_rate\n",
      "0      Queanbeyan Surrounds                2.6\n",
      "1  Unanderra - Mount Kembla                4.2\n",
      "2     Bright - Mount Beauty                1.8\n",
      "3                  Montrose                3.1\n",
      "4           Werribee - West                6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rc/ddmw432j4cj3k9y_h6wn3npw0000gn/T/ipykernel_90214/3437119548.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_columns.loc[:, 'SA2_name'] = selected_columns['SA2_name'].str.replace(r'^\\d+:\\s*', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# remove numbers and colon from the 'SA2 name' column\n",
    "selected_columns.loc[:, 'SA2_name'] = selected_columns['SA2_name'].str.replace(r'^\\d+:\\s*', '', regex=True)\n",
    "\n",
    "# display the DataFrame with the cleaned 'SA2_name'\n",
    "print(selected_columns.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            SA2_name|unemployment_rate|\n",
      "+--------------------+-----------------+\n",
      "|Queanbeyan Surrounds|              2.6|\n",
      "|Unanderra - Mount...|              4.2|\n",
      "|Bright - Mount Be...|              1.8|\n",
      "|            Montrose|              3.1|\n",
      "|     Werribee - West|              6.2|\n",
      "+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert Pandas DataFrame to Spark DataFrame\n",
    "unemployment = spark.createDataFrame(selected_columns)\n",
    "unemployment.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame as a Parquet file\n",
    "unemployment.write.parquet('../data/curated/unemployment', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge income and population\n",
    "df_income_pop = population.join(income_pyspark, on='SA2_name', how='inner')\n",
    "\n",
    "# merge the above with unemployment rate\n",
    "df_income_pop_unemp = df_income_pop.join(unemployment, on='SA2_name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_income_pop_unemp_pandas = df_income_pop_unemp.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_pop_unemp_post = pd.merge(df_income_pop_unemp_pandas, postcode_sa2_geo, on='SA2_name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_name</th>\n",
       "      <th>average_population</th>\n",
       "      <th>earners</th>\n",
       "      <th>income</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>geometry</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kiama Downs - Minnamurra</td>\n",
       "      <td>6002.0</td>\n",
       "      <td>3,633</td>\n",
       "      <td>255,198,601</td>\n",
       "      <td>3.2</td>\n",
       "      <td>POLYGON ((150.84893 -34.63408, 150.84936 -34.6...</td>\n",
       "      <td>2533</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lismore</td>\n",
       "      <td>15079.5</td>\n",
       "      <td>7,696</td>\n",
       "      <td>400,449,143</td>\n",
       "      <td>6.7</td>\n",
       "      <td>POLYGON ((153.25828 -28.80043, 153.25836 -28.7...</td>\n",
       "      <td>2480</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raymond Terrace</td>\n",
       "      <td>14802.0</td>\n",
       "      <td>7,118</td>\n",
       "      <td>390,229,618</td>\n",
       "      <td>7.2</td>\n",
       "      <td>POLYGON ((151.74096 -32.75945, 151.74258 -32.7...</td>\n",
       "      <td>2322</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raymond Terrace</td>\n",
       "      <td>14802.0</td>\n",
       "      <td>7,118</td>\n",
       "      <td>390,229,618</td>\n",
       "      <td>7.2</td>\n",
       "      <td>POLYGON ((151.74096 -32.75945, 151.74258 -32.7...</td>\n",
       "      <td>2324</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Niagara Park - Lisarow</td>\n",
       "      <td>8215.5</td>\n",
       "      <td>4,877</td>\n",
       "      <td>315,596,744</td>\n",
       "      <td>3.9</td>\n",
       "      <td>POLYGON ((151.34439 -33.38197, 151.34385 -33.3...</td>\n",
       "      <td>2250</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SA2_name  average_population earners       income  \\\n",
       "0  Kiama Downs - Minnamurra              6002.0   3,633  255,198,601   \n",
       "1                   Lismore             15079.5   7,696  400,449,143   \n",
       "2           Raymond Terrace             14802.0   7,118  390,229,618   \n",
       "3           Raymond Terrace             14802.0   7,118  390,229,618   \n",
       "4    Niagara Park - Lisarow              8215.5   4,877  315,596,744   \n",
       "\n",
       "   unemployment_rate                                           geometry  \\\n",
       "0                3.2  POLYGON ((150.84893 -34.63408, 150.84936 -34.6...   \n",
       "1                6.7  POLYGON ((153.25828 -28.80043, 153.25836 -28.7...   \n",
       "2                7.2  POLYGON ((151.74096 -32.75945, 151.74258 -32.7...   \n",
       "3                7.2  POLYGON ((151.74096 -32.75945, 151.74258 -32.7...   \n",
       "4                3.9  POLYGON ((151.34439 -33.38197, 151.34385 -33.3...   \n",
       "\n",
       "   postcode state  \n",
       "0      2533   NSW  \n",
       "1      2480   NSW  \n",
       "2      2322   NSW  \n",
       "3      2324   NSW  \n",
       "4      2250   NSW  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_income_pop_unemp_post.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing on merged external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_income_pop_unemp_post:\n",
      "SA2_name                object\n",
      "average_population     float64\n",
      "earners                 object\n",
      "income                  object\n",
      "unemployment_rate      float64\n",
      "geometry              geometry\n",
      "postcode                 int64\n",
      "state                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check the data type\n",
    "print('df_income_pop_unemp_post:')\n",
    "print(df_income_pop_unemp_post.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2_name               0\n",
      "average_population     0\n",
      "earners               47\n",
      "income                47\n",
      "unemployment_rate      0\n",
      "geometry               0\n",
      "postcode               0\n",
      "state                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove the comma and then convert it to numerical value\n",
    "df_income_pop_unemp_post['income'] = pd.to_numeric(df_income_pop_unemp_post['income'].\\\n",
    "                                                   replace({',': ''}, regex=True), errors='coerce')\n",
    "df_income_pop_unemp_post['earners'] = pd.to_numeric(df_income_pop_unemp_post['earners'].\\\n",
    "                                                    replace({',': ''}, regex=True), errors='coerce')\n",
    "\n",
    "# check the number of missing value\n",
    "missing_values = df_income_pop_unemp_post.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2_name                object\n",
      "average_population     float64\n",
      "earners                  int64\n",
      "income                   int64\n",
      "unemployment_rate      float64\n",
      "geometry              geometry\n",
      "postcode                 int64\n",
      "state                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# replace NaN with 0\n",
    "df_income_pop_unemp_post['income'].fillna(0, inplace=True)\n",
    "df_income_pop_unemp_post['earners'].fillna(0, inplace=True)\n",
    "\n",
    "# convert to int data type\n",
    "df_income_pop_unemp_post['income'] = df_income_pop_unemp_post['income'].astype(int)\n",
    "df_income_pop_unemp_post['earners'] = df_income_pop_unemp_post['earners'].astype(int)\n",
    "\n",
    "# check the data type again\n",
    "print(df_income_pop_unemp_post.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_population</th>\n",
       "      <th>earners</th>\n",
       "      <th>income</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4931.000000</td>\n",
       "      <td>4931.000000</td>\n",
       "      <td>4.931000e+03</td>\n",
       "      <td>4931.000000</td>\n",
       "      <td>4931.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9829.516934</td>\n",
       "      <td>5521.036504</td>\n",
       "      <td>3.745733e+08</td>\n",
       "      <td>4.687447</td>\n",
       "      <td>4029.228351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6003.559309</td>\n",
       "      <td>3500.707813</td>\n",
       "      <td>2.971973e+08</td>\n",
       "      <td>2.714191</td>\n",
       "      <td>1524.137579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.893000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5101.000000</td>\n",
       "      <td>2787.000000</td>\n",
       "      <td>1.582013e+08</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2737.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8263.500000</td>\n",
       "      <td>4619.000000</td>\n",
       "      <td>2.870109e+08</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>3858.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13522.000000</td>\n",
       "      <td>7895.000000</td>\n",
       "      <td>5.182709e+08</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>5108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28645.500000</td>\n",
       "      <td>16374.000000</td>\n",
       "      <td>2.281369e+09</td>\n",
       "      <td>66.700000</td>\n",
       "      <td>7470.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       average_population       earners        income  unemployment_rate  \\\n",
       "count         4931.000000   4931.000000  4.931000e+03        4931.000000   \n",
       "mean          9829.516934   5521.036504  3.745733e+08           4.687447   \n",
       "std           6003.559309   3500.707813  2.971973e+08           2.714191   \n",
       "min              0.000000      3.000000  5.893000e+04           0.000000   \n",
       "25%           5101.000000   2787.000000  1.582013e+08           3.400000   \n",
       "50%           8263.500000   4619.000000  2.870109e+08           4.100000   \n",
       "75%          13522.000000   7895.000000  5.182709e+08           5.350000   \n",
       "max          28645.500000  16374.000000  2.281369e+09          66.700000   \n",
       "\n",
       "          postcode  \n",
       "count  4931.000000  \n",
       "mean   4029.228351  \n",
       "std    1524.137579  \n",
       "min     800.000000  \n",
       "25%    2737.500000  \n",
       "50%    3858.000000  \n",
       "75%    5108.000000  \n",
       "max    7470.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete rows where 'earners' or 'income' is 0\n",
    "df_income_pop_unemp_post = df_income_pop_unemp_post[(df_income_pop_unemp_post['earners'] != 0) \n",
    "                                                    & (df_income_pop_unemp_post['income'] != 0)]\n",
    "df_income_pop_unemp_post.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4931, 8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_income_pop_unemp_post.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame as a CSV file\n",
    "df_income_pop_unemp_post.to_csv('../data/curated/merged_datasets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the geometry column\n",
    "df_income_pop_unemp_post = df_income_pop_unemp_post.drop(columns=['geometry'])\n",
    "\n",
    "# convert the DataFrame as a Parquet file\n",
    "df_income_pop_unemp_post = spark.createDataFrame(df_income_pop_unemp_post)\n",
    "\n",
    "# save the DataFrame as a Parquet file\n",
    "df_income_pop_unemp_post.write.parquet('../data/curated/merged_external', mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
